from fastapi import FastAPI, UploadFile, File, HTTPException, Depends, Form, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.openapi.docs import get_swagger_ui_html
from fastapi.openapi.utils import get_openapi
from fastapi.security import HTTPBasic, HTTPBasicCredentials
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import sys
import shutil
import secrets
import subprocess
from pathlib import Path
from datetime import datetime
import pandas as pd
import uuid
import time
import pdfplumber
from docx import Document
from PIL import Image
import pytesseract
# å¯¼å…¥OCRé…ç½®æ¨¡å—
from ocr_config import setup_ocr_environment

# è®¾ç½®OCRç¯å¢ƒ
setup_ocr_environment()
import io

# å°†å½“å‰ç›®å½•åŠ å…¥Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# å¯¼å…¥ç°æœ‰çš„å¤„ç†è„šæœ¬
from convert_excel_to_csv import process_excel_to_standard_csv, extract_valve_info
from valve_model_generator import generate_valve_models, analyze_valve_missing_params, parse_valve_info, parse_valve_info_from_combined
from generate_quotes import process_inquiry_file, generate_summary_report
from default_rules import DefaultRulesManager
from csv_utils import safe_read_csv, safe_to_csv
from ocr_correction import OCRCorrector
from enhanced_quote_processor import process_quote_with_enhanced_matching, generate_multi_brand_quote
from structured_quote_generator import generate_structured_quote

# ------------------ OpenAPI / Swagger é…ç½® ------------------
tags_metadata = [
    {"name": "auth", "description": "è´¦æˆ·ç™»å½•ä¸ç®¡ç†ç›¸å…³æ¥å£"},
    {"name": "rules", "description": "é»˜è®¤è§„åˆ™è·å–ä¸ä¿å­˜"},
    {"name": "interactive", "description": "äº¤äº’å¼å‹å·è¡¥å…¨ä¸æŠ¥ä»·æµç¨‹"},
    {"name": "upload", "description": "ä»·æ ¼è¡¨ / è¯¢ä»·è¡¨ / OCR å›¾ç‰‡ä¸Šä¼ è§£æ"},
    {"name": "ocr", "description": "OCR è¯†åˆ«ä¸æ–‡æœ¬çº é”™"},
    {"name": "files", "description": "ç”¨æˆ·æ–‡ä»¶åˆ—å‡ºä¸ç”Ÿæˆç»“æœ"}
]

app = FastAPI(
    title="é˜€é—¨æŠ¥ä»·ç³»ç»Ÿ API",
    description="ç”¨äºé˜€é—¨è¯¢ä»·è§£æã€å‹å·ç”Ÿæˆã€ä»·æ ¼åŒ¹é…ä¸æŠ¥ä»·å•ç”Ÿæˆçš„åç«¯æ¥å£ã€‚\n\n" \
                "åŒ…å«ï¼š\n" \
                "1. è´¦æˆ·ç®¡ç†ä¸è®¤è¯ (HTTP Basic)\n" \
                "2. è¯¢ä»· / ä»·æ ¼è¡¨æ–‡ä»¶ä¸Šä¼ è§£æ\n" \
                "3. æ™ºèƒ½å‹å·è¡¥å…¨ + äº¤äº’å¼å‚æ•°é€‰æ‹©\n" \
                "4. æŠ¥ä»·ç”Ÿæˆä¸æ±‡æ€»\n" \
                "5. OCR å›¾ç‰‡è¯†åˆ«åŠçº é”™\n",
    version="1.0.0",
    openapi_url="/openapi.json",
    docs_url="/docs",          # é»˜è®¤ Swagger UI
    redoc_url="/redoc",         # ReDoc æ–‡æ¡£
    openapi_tags=tags_metadata,
    swagger_ui_parameters={
        "defaultModelsExpandDepth": 0,
        "displayRequestDuration": True,
        "tryItOutEnabled": True
    }
)


# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8000", "http://127.0.0.1:8000"],  # æŒ‡å®šå…·ä½“çš„å‰ç«¯æºåœ°å€
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰HTTPå¤´
    expose_headers=["*"],  # æš´éœ²æ‰€æœ‰å¤´ä¿¡æ¯
    max_age=86400,  # é¢„æ£€è¯·æ±‚ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
)

# åŸºç¡€è®¤è¯
security = HTTPBasic()

# è´¦æˆ·æ–‡ä»¶è·¯å¾„
ACCOUNTS_FILE = os.path.join(current_dir, "accounts.txt")

# æ•°æ®å­˜å‚¨æ ¹ç›®å½• - ä½¿ç”¨quote-systemç›®å½•ä¸‹çš„merchant_data
DATA_ROOT = os.path.abspath(os.path.join(current_dir, "merchant_data"))
print(f"ğŸ”§ [INIT] æ•°æ®å­˜å‚¨æ ¹ç›®å½•: {DATA_ROOT}")

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(DATA_ROOT, exist_ok=True)

# äº¤äº’å¼æ‰¹æ¬¡æ•°æ®å­˜å‚¨ï¼ˆå†…å­˜ç¼“å­˜ï¼‰
interactive_batches = {}

def get_rules_manager():
    """è·å–è§„åˆ™ç®¡ç†å™¨å®ä¾‹"""
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_root = os.path.abspath(os.path.join(current_dir, "merchant_data"))
    return DefaultRulesManager(data_root)

class Account(BaseModel):
    username: str
    password: str

class DefaultRules(BaseModel):
    product_defaults: Dict[str, Dict[str, str]]
    custom_products: Dict[str, Dict[str, str]]

class InteractiveChoice(BaseModel):
    valve_info: Dict[str, Any]
    selections: Dict[str, str]

# æ–°å¢äº¤äº’å¼æ‰¹é‡å¤„ç†ç›¸å…³çš„æ•°æ®æ¨¡å‹
class InteractiveBatch(BaseModel):
    batch_id: str
    incomplete_items: List[Dict[str, Any]]
    completed_items: List[Dict[str, Any]]
    current_index: int
    total_count: int

class InteractiveSelection(BaseModel):
    batch_id: str
    item_index: int
    selections: Dict[str, str]

class InteractiveItem(BaseModel):
    index: int
    name: str
    specs: str
    quantity: str
    missing_params: List[str]
    valve_info: Dict[str, Any]

# ------------- é€šç”¨/å“åº”æ¨¡å‹ -------------
class MessageResponse(BaseModel):
    message: str

class LoginResponse(BaseModel):
    username: str
    is_admin: bool

class CreateAccountResponse(MessageResponse):
    pass

class FileListResponse(BaseModel):
    price_tables: List[str]
    inquiry_tables: List[str]
    quotes: List[str]

class OCRProcessResponse(BaseModel):
    message: str
    original_text: str
    corrected_text: str
    extracted_data: List[Dict[str, Any]]
    statistics: Dict[str, Any]

class UploadResponse(BaseModel):
    message: str
    filename: str

class PriceUploadResponse(UploadResponse):
    brands: List[str]

class InteractiveStartProgress(BaseModel):
    current: int
    total: int

class InteractiveStartResponse(BaseModel):
    need_interaction: bool
    batch_id: str
    message: Optional[str] = None
    current_item: Optional[InteractiveItem] = None
    progress: Optional[InteractiveStartProgress] = None

def verify_credentials(credentials: HTTPBasicCredentials = Depends(security)):
    """éªŒè¯ç”¨æˆ·å‡­æ®"""
    if not os.path.exists(ACCOUNTS_FILE):
        raise HTTPException(status_code=401, detail="è´¦æˆ·ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    with open(ACCOUNTS_FILE, 'r') as f:
        for line in f:
            line = line.strip()
            if line and ':' in line:
                try:
                    stored_user, stored_pass = line.split(':', 1)
                    if credentials.username == stored_user and credentials.password == stored_pass:
                        return credentials.username
                except ValueError:
                    continue
    
    raise HTTPException(status_code=401, detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

# å¯é€‰ï¼šå—ä¿æŠ¤çš„æ–‡æ¡£å…¥å£ï¼ˆè®¿é—® /secure-docs éœ€ç™»å½•ï¼‰
@app.get("/secure-docs", include_in_schema=False)
def secure_docs(username: str = Depends(verify_credentials)):
    """éœ€è¦ç™»å½•æ‰èƒ½è®¿é—®çš„ Swagger UI é¡µé¢"""
    return get_swagger_ui_html(openapi_url="/openapi.json", title="Secure Swagger UI")

def is_admin(username: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜"""
    return username == "admin"

@app.get("/", response_model=MessageResponse, summary="å¥åº·æ£€æŸ¥ / æ ¹ä¿¡æ¯", tags=["auth"], description="è¿”å› API åŸºæœ¬å¯ç”¨çŠ¶æ€ã€‚")
async def root():
    return {"message": "æŠ¥ä»·ç³»ç»ŸAPI æ­£å¸¸è¿è¡Œ"}

@app.post("/api/login", response_model=LoginResponse, summary="ç”¨æˆ·ç™»å½•", tags=["auth"], description="ä½¿ç”¨ HTTP Basic è®¤è¯ç™»å½•ï¼ŒæˆåŠŸè¿”å›ç”¨æˆ·ååŠæ˜¯å¦ä¸ºç®¡ç†å‘˜æ ‡è®°ã€‚")
async def login(credentials: HTTPBasicCredentials = Depends(security)):
    username = verify_credentials(credentials)
    return {"username": username, "is_admin": is_admin(username)}

@app.get("/api/accounts", response_model=List[str], summary="åˆ—å‡ºå…¨éƒ¨è´¦æˆ·", tags=["auth"], description="ä»…ç®¡ç†å‘˜å¯ç”¨ï¼Œè¿”å›ç³»ç»Ÿä¸­æ‰€æœ‰æ™®é€šä¸ç®¡ç†å‘˜è´¦å·ç”¨æˆ·ååˆ—è¡¨ã€‚")
async def list_accounts(username: str = Depends(verify_credentials)):
    if not is_admin(username):
        raise HTTPException(status_code=403, detail="æ— æƒé™")
    
    if not os.path.exists(ACCOUNTS_FILE):
        return []
    
    accounts = []
    with open(ACCOUNTS_FILE, 'r') as f:
        for line in f:
            if ':' in line:
                user, _ = line.strip().split(':', 1)
                accounts.append(user)
    return accounts

@app.post("/api/accounts", response_model=CreateAccountResponse, summary="åˆ›å»ºè´¦æˆ·", tags=["auth"], description="ä»…ç®¡ç†å‘˜ï¼šåˆ›å»ºä¸€ä¸ªæ–°è´¦æˆ·ï¼Œå¹¶åˆå§‹åŒ–å…¶é»˜è®¤è§„åˆ™ä¸ç›®å½•ç»“æ„ã€‚")
async def create_account(account: Account, username: str = Depends(verify_credentials)):
    if not is_admin(username):
        raise HTTPException(status_code=403, detail="æ— æƒé™")
    
    if ':' in account.username:
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åä¸èƒ½åŒ…å«å†’å·")
    if not account.username.strip():
        raise HTTPException(status_code=400, detail="ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
    if not account.password.strip():
        raise HTTPException(status_code=400, detail="å¯†ç ä¸èƒ½ä¸ºç©º")
    
    # æ£€æŸ¥è´¦æˆ·æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(ACCOUNTS_FILE):
        with open(ACCOUNTS_FILE, 'r') as f:
            for line in f:
                if ':' in line:
                    stored_user, _ = line.strip().split(':', 1)
                    if stored_user == account.username:
                        raise HTTPException(status_code=400, detail="ç”¨æˆ·å·²å­˜åœ¨")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦éœ€è¦æ·»åŠ æ¢è¡Œç¬¦
    need_newline = False
    if os.path.exists(ACCOUNTS_FILE) and os.path.getsize(ACCOUNTS_FILE) > 0:
        with open(ACCOUNTS_FILE, 'rb') as f:
            f.seek(-1, 2)
            last_char = f.read(1)
            if last_char != b'\n':
                need_newline = True
    
    # æ·»åŠ æ–°è´¦æˆ·
    with open(ACCOUNTS_FILE, 'a') as f:
        if need_newline:
            f.write('\n')
        f.write(f"{account.username}:{account.password}\n")
    
    # åˆ›å»ºç”¨æˆ·æ•°æ®ç›®å½•
    user_dir = os.path.join(DATA_ROOT, account.username)
    os.makedirs(user_dir, exist_ok=True)
    os.makedirs(os.path.join(user_dir, "ä»·æ ¼è¡¨"), exist_ok=True)
    os.makedirs(os.path.join(user_dir, "è¯¢ä»·è¡¨"), exist_ok=True)
    os.makedirs(os.path.join(user_dir, "æŠ¥ä»·å•"), exist_ok=True)
    
    # ä¸ºæ–°ç”¨æˆ·åˆ›å»ºé»˜è®¤è§„åˆ™æ–‡ä»¶
    rules_manager = get_rules_manager()
    rules_manager.create_default_rules_for_new_user(account.username)
    
    return {"message": "è´¦æˆ·åˆ›å»ºæˆåŠŸ"}

@app.delete("/api/accounts/{account_name}", response_model=MessageResponse, summary="åˆ é™¤è´¦æˆ·", tags=["auth"], description="ä»…ç®¡ç†å‘˜ï¼šåˆ é™¤æŒ‡å®šæ™®é€šè´¦æˆ·åŠå…¶æ•°æ®ã€‚")
async def delete_account(account_name: str, username: str = Depends(verify_credentials)):
    if not is_admin(username):
        raise HTTPException(status_code=403, detail="æ— æƒé™")
    
    if account_name == "admin":
        raise HTTPException(status_code=400, detail="ä¸èƒ½åˆ é™¤ç®¡ç†å‘˜è´¦æˆ·")
    
    # ä»è´¦æˆ·æ–‡ä»¶ä¸­åˆ é™¤
    if os.path.exists(ACCOUNTS_FILE):
        lines = []
        with open(ACCOUNTS_FILE, 'r') as f:
            lines = f.readlines()
        
        with open(ACCOUNTS_FILE, 'w') as f:
            for line in lines:
                if not line.startswith(account_name + ':'):
                    f.write(line)
    
    # åˆ é™¤ç”¨æˆ·æ•°æ®ç›®å½•
    user_dir = os.path.join(DATA_ROOT, account_name)
    if os.path.exists(user_dir):
        shutil.rmtree(user_dir)
    
    return {"message": "è´¦æˆ·åˆ é™¤æˆåŠŸ"}

# é»˜è®¤è§„åˆ™ç®¡ç†æ¥å£
@app.get("/api/default-rules/options", summary="è·å–è§„åˆ™å¯é€‰é¡¹", tags=["rules"], description="è¿”å›å‰ç«¯æ„å»ºä¸‹æ‹‰é€‰æ‹©æ‰€éœ€çš„æ‰€æœ‰é»˜è®¤è§„åˆ™å­—æ®µä¸å€™é€‰å€¼ã€‚")
async def get_rule_options(username: str = Depends(verify_credentials)):
    rules_manager = get_rules_manager()
    return rules_manager.get_options_for_frontend()

@app.get("/api/default-rules", summary="è·å–å½“å‰ç”¨æˆ·é»˜è®¤è§„åˆ™", tags=["rules"], description="è¯»å–å¹¶è¿”å›å½“å‰ç™»å½•ç”¨æˆ·ä¿å­˜çš„é»˜è®¤è§„åˆ™é…ç½®ã€‚")
async def get_user_default_rules(username: str = Depends(verify_credentials)):
    rules_manager = get_rules_manager()
    print(f"ğŸ” [API] è·å–ç”¨æˆ·é»˜è®¤è§„åˆ™: username={username}")
    return rules_manager.load_user_rules(username)

@app.post("/api/default-rules", response_model=MessageResponse, summary="ä¿å­˜å½“å‰ç”¨æˆ·é»˜è®¤è§„åˆ™", tags=["rules"], description="è¦†ç›–ä¿å­˜å½“å‰ç™»å½•ç”¨æˆ·çš„é»˜è®¤è§„åˆ™é…ç½®ã€‚")
async def save_user_default_rules(rules: DefaultRules, username: str = Depends(verify_credentials)):
    rules_manager = get_rules_manager()
    print(f"ğŸ’¾ [API] ä¿å­˜ç”¨æˆ·é»˜è®¤è§„åˆ™: username={username}")
    success = rules_manager.save_user_rules(username, rules.dict())
    if success:
        return {"message": "é»˜è®¤è§„åˆ™ä¿å­˜æˆåŠŸ"}
    else:
        raise HTTPException(status_code=500, detail="ä¿å­˜é»˜è®¤è§„åˆ™å¤±è´¥")

@app.post("/api/interactive-match")
async def interactive_match(choice: InteractiveChoice, username: str = Depends(verify_credentials)):
    """äº¤äº’å¼åŒ¹é…å¤„ç†"""
    rules_manager = get_rules_manager()
    print(f"ğŸ”§ [API] äº¤äº’å¼åŒ¹é…: username={username}")
    
    # åº”ç”¨ç”¨æˆ·é€‰æ‹©
    valve_info = choice.valve_info.copy()
    valve_info.update(choice.selections)
    
    # ä½¿ç”¨é»˜è®¤è§„åˆ™ç®¡ç†å™¨å¤„ç†
    completed_info = rules_manager.apply_default_rules(username, valve_info)
    
    return {
        "message": "åŒ¹é…å®Œæˆ",
        "valve_info": completed_info
    }

@app.post("/api/get-interactive-options")
async def get_interactive_options(valve_info: Dict[str, Any], username: str = Depends(verify_credentials)):
    """è·å–äº¤äº’å¼é€‰æ‹©é€‰é¡¹"""
    rules_manager = get_rules_manager()
    options = rules_manager.create_interactive_options(valve_info)
    return options

@app.post("/api/start-interactive-quote", response_model=InteractiveStartResponse, summary="å¯åŠ¨äº¤äº’å¼æŠ¥ä»·åˆ†æ", tags=["interactive"], description="è§£æè¯¢ä»·è¡¨å¹¶æ‰¾å‡ºéœ€è¦äººå·¥è¡¥å…¨å‚æ•°çš„äº§å“ï¼Œè¿”å›ç¬¬ä¸€é¡¹å¾…äº¤äº’æ¡ç›®ã€‚å…¨éƒ¨å®Œæ•´åˆ™ç›´æ¥æ ‡è®°æ— éœ€äº¤äº’ã€‚")
async def start_interactive_quote(
    price_file: str = Form(...),
    inquiry_file: str = Form(...),
    username: str = Depends(verify_credentials)
):
    """å¼€å§‹äº¤äº’å¼æŠ¥ä»·æµç¨‹ï¼Œåˆ†æè¯¢ä»·è¡¨å¹¶è¿”å›éœ€è¦ç”¨æˆ·é€‰æ‹©çš„äº§å“åˆ—è¡¨"""
    # ç¡®ä¿åœ¨ä¸€ä¸ªæœ‰æ•ˆçš„ç›®å½•ä¸­è¿è¡Œ
    try:
        original_dir = os.getcwd()
    except FileNotFoundError:
        # å¦‚æœå½“å‰ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ‡æ¢åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
        original_dir = os.path.dirname(os.path.abspath(__file__))
        os.chdir(original_dir)
        print(f"ğŸ”„ [INTERACTIVE] åˆ‡æ¢åˆ°æœ‰æ•ˆç›®å½•: {original_dir}")
    
    work_dir = None
    
    try:
        print(f"ğŸš€ [INTERACTIVE] å¼€å§‹äº¤äº’å¼æŠ¥ä»·æµç¨‹")
        print(f"ğŸ“ [INTERACTIVE] ç”¨æˆ·: {username}")
        print(f"ğŸ’° [INTERACTIVE] ä»·æ ¼æ–‡ä»¶: {price_file}")
        print(f"ğŸ“‹ [INTERACTIVE] è¯¢ä»·æ–‡ä»¶: {inquiry_file}")
        
        user_dir = os.path.join(DATA_ROOT, username)
        inquiry_path = os.path.join(user_dir, "è¯¢ä»·è¡¨", inquiry_file)
        
        # æ£€æŸ¥è¯¢ä»·æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(inquiry_path):
            raise HTTPException(status_code=404, detail=f"è¯¢ä»·æ–‡ä»¶ä¸å­˜åœ¨: {inquiry_file}")
        
        # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        work_dir = os.path.join(user_dir, f"temp_interactive_{timestamp}")
        os.makedirs(work_dir, exist_ok=True)
        
        try:
            # å¤åˆ¶è¯¢ä»·æ–‡ä»¶åˆ°å·¥ä½œç›®å½•
            inquiry_dst = os.path.join(work_dir, "å®¢æˆ·è¯¢ä»·è¡¨")
            os.makedirs(inquiry_dst, exist_ok=True)
            inquiry_file_dst = os.path.join(inquiry_dst, inquiry_file)
            shutil.copy2(inquiry_path, inquiry_file_dst)
            
            # åˆ‡æ¢åˆ°å·¥ä½œç›®å½•
            os.chdir(work_dir)
            
            # åˆ›å»ºæ ‡å‡†æ ¼å¼ç›®å½•
            os.makedirs("è§„èŒƒåå®¢æˆ·è¯¢ä»·è¡¨æ•°æ®", exist_ok=True)
            
            # è½¬æ¢æ–‡ä»¶æ ¼å¼
            if inquiry_file.endswith(('.xlsx', '.xls')):
                # Excelæ–‡ä»¶è½¬æ¢
                input_file = os.path.join("å®¢æˆ·è¯¢ä»·è¡¨", inquiry_file)
                output_file = os.path.join("è§„èŒƒåå®¢æˆ·è¯¢ä»·è¡¨æ•°æ®", f"{Path(inquiry_file).stem}_æ ‡å‡†æ ¼å¼.csv")
                process_excel_to_standard_csv(input_file, output_file)
            else:
                # CSVæ–‡ä»¶ç›´æ¥å¤åˆ¶
                input_file = os.path.join("å®¢æˆ·è¯¢ä»·è¡¨", inquiry_file)
                output_file = os.path.join("è§„èŒƒåå®¢æˆ·è¯¢ä»·è¡¨æ•°æ®", f"{Path(inquiry_file).stem}_æ ‡å‡†æ ¼å¼.csv")
                shutil.copy2(input_file, output_file)
            
            # è¯»å–æ ‡å‡†æ ¼å¼çš„è¯¢ä»·è¡¨
            csv_files = [f for f in os.listdir("è§„èŒƒåå®¢æˆ·è¯¢ä»·è¡¨æ•°æ®") if f.endswith('.csv')]
            if not csv_files:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°è½¬æ¢åçš„CSVæ–‡ä»¶")
            
            # åˆ†æç¬¬ä¸€ä¸ªCSVæ–‡ä»¶ä¸­çš„äº§å“
            csv_file = csv_files[0]
            csv_path = os.path.join("è§„èŒƒåå®¢æˆ·è¯¢ä»·è¡¨æ•°æ®", csv_file)
            df = safe_read_csv(csv_path)
            
            print(f"ğŸ“Š [INTERACTIVE] è¯»å–è¯¢ä»·è¡¨: {len(df)} è¡Œæ•°æ®")
            
            # åˆ†ææ¯ä¸ªäº§å“ï¼Œæ‰¾å‡ºéœ€è¦äº¤äº’é€‰æ‹©çš„äº§å“
            incomplete_items = []
            completed_items = []
            
            for index, row in df.iterrows():
                if pd.isna(row['å“å']) or row['å“å'] == 'åˆè®¡':
                    continue
                
                print(f"ğŸ” [INTERACTIVE] åˆ†æç¬¬ {index+1} è¡Œ: {row['å“å']}")
                
                # åˆ†æç¼ºå¤±å‚æ•°
                analysis_result = analyze_valve_missing_params(row['å“å'], row['è§„æ ¼å‹å·'])
                
                if analysis_result:
                    # éœ€è¦äº¤äº’é€‰æ‹©
                    item = {
                        'index': index,
                        'name': str(row['å“å']),
                        'specs': str(row['è§„æ ¼å‹å·']),
                        'quantity': str(row.get('æ•°é‡', '')),
                        'missing_params': analysis_result['missing_params'],
                        'valve_info': analysis_result['valve_info']
                    }
                    incomplete_items.append(item)
                    print(f"â“ [INTERACTIVE] éœ€è¦äº¤äº’: {item['name']} - ç¼ºå¤±å‚æ•°: {item['missing_params']}")
                else:
                    # ä¸éœ€è¦äº¤äº’é€‰æ‹©
                    completed_items.append({
                        'index': index,
                        'name': str(row['å“å']),
                        'specs': str(row['è§„æ ¼å‹å·']),
                        'quantity': str(row.get('æ•°é‡', ''))
                    })
                    print(f"âœ… [INTERACTIVE] æ— éœ€äº¤äº’: {row['å“å']}")
            
            # ç”Ÿæˆæ‰¹æ¬¡ID
            batch_id = str(uuid.uuid4())
            
            # åˆ›å»ºæ‰¹æ¬¡æ•°æ®
            batch_data = {
                'batch_id': batch_id,
                'username': username,
                'price_file': price_file,
                'inquiry_file': inquiry_file,
                'work_dir': work_dir,
                'original_dir': original_dir,
                'csv_file': csv_file,
                'incomplete_items': incomplete_items,
                'completed_items': completed_items,
                'current_index': 0,
                'total_count': len(incomplete_items),
                'user_selections': {}  # å­˜å‚¨ç”¨æˆ·çš„é€‰æ‹©
            }
            
            # å­˜å‚¨æ‰¹æ¬¡æ•°æ®
            interactive_batches[batch_id] = batch_data
            
            print(f"ğŸ“Š [INTERACTIVE] åˆ†æå®Œæˆ:")
            print(f"   éœ€è¦äº¤äº’çš„äº§å“: {len(incomplete_items)} ä¸ª")
            print(f"   æ— éœ€äº¤äº’çš„äº§å“: {len(completed_items)} ä¸ª")
            print(f"   æ‰¹æ¬¡ID: {batch_id}")
            
            if not incomplete_items:
                # æ²¡æœ‰éœ€è¦äº¤äº’çš„äº§å“ï¼Œç›´æ¥ç”ŸæˆæŠ¥ä»·
                return {
                    "need_interaction": False,
                    "message": "æ‰€æœ‰äº§å“å‚æ•°å®Œæ•´ï¼Œæ— éœ€äº¤äº’é€‰æ‹©",
                    "batch_id": batch_id
                }
            
            # è¿”å›ç¬¬ä¸€ä¸ªéœ€è¦äº¤äº’çš„äº§å“
            first_item = incomplete_items[0]
            return {
                "need_interaction": True,
                "batch_id": batch_id,
                "current_item": first_item,
                "progress": {
                    "current": 1,
                    "total": len(incomplete_items)
                }
            }
            
        except Exception as e:
            # æ¸…ç†å·¥ä½œç›®å½•
            os.chdir(original_dir)
            if work_dir and os.path.exists(work_dir):
                shutil.rmtree(work_dir)
            raise e
            
    except Exception as e:
        # ç¡®ä¿è¿”å›åˆ°åŸå§‹ç›®å½•
        try:
            os.chdir(original_dir)
        except Exception as cd_error:
            print(f"âš ï¸  [INTERACTIVE] æ— æ³•è¿”å›åŸå§‹ç›®å½•: {cd_error}")
            # å°è¯•åˆ‡æ¢åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
            script_dir = os.path.dirname(os.path.abspath(__file__))
            try:
                os.chdir(script_dir)
                print(f"ğŸ”„ [INTERACTIVE] åˆ‡æ¢åˆ°è„šæœ¬ç›®å½•: {script_dir}")
            except Exception:
                pass
        
        # æ¸…ç†å¯èƒ½åˆ›å»ºçš„å·¥ä½œç›®å½•
        if work_dir and os.path.exists(work_dir):
            try:
                shutil.rmtree(work_dir)
                print(f"ğŸ—‘ï¸  [INTERACTIVE] æ¸…ç†ä¸´æ—¶ç›®å½•: {work_dir}")
            except Exception as cleanup_error:
                print(f"âš ï¸  [INTERACTIVE] æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {cleanup_error}")
                
        print(f"âŒ [INTERACTIVE] å¯åŠ¨äº¤äº’å¼æµç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨äº¤äº’å¼æµç¨‹å¤±è´¥: {str(e)}")

@app.post("/api/submit-interactive-selection")
async def submit_interactive_selection(
    selection: InteractiveSelection,
    username: str = Depends(verify_credentials)
):
    """æäº¤å•ä¸ªäº§å“çš„å‚æ•°é€‰æ‹©"""
    try:
        print(f"ğŸ“ [INTERACTIVE] æäº¤å‚æ•°é€‰æ‹©: batch_id={selection.batch_id}")
        
        # è·å–æ‰¹æ¬¡æ•°æ®
        if selection.batch_id not in interactive_batches:
            raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")
        
        batch_data = interactive_batches[selection.batch_id]
        
        # éªŒè¯ç”¨æˆ·æƒé™
        if batch_data['username'] != username:
            raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®æ­¤æ‰¹æ¬¡")
        
        # éªŒè¯é¡¹ç›®ç´¢å¼•
        if selection.item_index >= len(batch_data['incomplete_items']):
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„é¡¹ç›®ç´¢å¼•")
        
        # ä¿å­˜ç”¨æˆ·é€‰æ‹©
        item_key = f"item_{selection.item_index}"
        batch_data['user_selections'][item_key] = selection.selections
        
        print(f"âœ… [INTERACTIVE] ä¿å­˜é€‰æ‹©: {selection.selections}")
        
        # æ›´æ–°å½“å‰ç´¢å¼•
        batch_data['current_index'] = selection.item_index + 1
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„é¡¹ç›®
        if batch_data['current_index'] < len(batch_data['incomplete_items']):
            # è¿”å›ä¸‹ä¸€ä¸ªéœ€è¦äº¤äº’çš„äº§å“
            next_item = batch_data['incomplete_items'][batch_data['current_index']]
            return {
                "completed": False,
                "next_item": next_item,
                "progress": {
                    "current": batch_data['current_index'] + 1,
                    "total": len(batch_data['incomplete_items'])
                }
            }
        else:
            # æ‰€æœ‰äº¤äº’å®Œæˆ
            return {
                "completed": True,
                "message": "æ‰€æœ‰å‚æ•°é€‰æ‹©å®Œæˆï¼Œå¯ä»¥ç”ŸæˆæŠ¥ä»·å•",
                "total_selections": len(batch_data['user_selections'])
            }
            
    except Exception as e:
        print(f"âŒ [INTERACTIVE] æäº¤é€‰æ‹©å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æäº¤é€‰æ‹©å¤±è´¥: {str(e)}")

@app.post("/api/complete-interactive-quote")
async def complete_interactive_quote(
    batch_id: str = Form(...),
    username: str = Depends(verify_credentials)
):
    """å®Œæˆæ‰€æœ‰äº¤äº’é€‰æ‹©åï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥ä»·å•"""
    try:
        print(f"ğŸ¯ [INTERACTIVE] å®Œæˆäº¤äº’å¼æŠ¥ä»·: batch_id={batch_id}")
        
        # è·å–æ‰¹æ¬¡æ•°æ®
        if batch_id not in interactive_batches:
            raise HTTPException(status_code=404, detail="æ‰¹æ¬¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")
        
        batch_data = interactive_batches[batch_id]
        
        # éªŒè¯ç”¨æˆ·æƒé™
        if batch_data['username'] != username:
            raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®æ­¤æ‰¹æ¬¡")
        
        # è·å–åŸå§‹ç›®å½•å’Œå·¥ä½œç›®å½•
        original_dir = batch_data.get('original_dir')
        work_dir = batch_data.get('work_dir')
        
        # éªŒè¯ç›®å½•æ˜¯å¦å­˜åœ¨
        if not original_dir or not os.path.exists(original_dir):
            # å¦‚æœåŸå§‹ç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•
            original_dir = os.path.dirname(os.path.abspath(__file__))
            print(f"ğŸ”„ [INTERACTIVE] åŸå§‹ç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨è„šæœ¬ç›®å½•: {original_dir}")
        
        if not work_dir or not os.path.exists(work_dir):
            raise HTTPException(status_code=500, detail="å·¥ä½œç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•å®ŒæˆæŠ¥ä»·")
        
        # åˆ‡æ¢åˆ°å·¥ä½œç›®å½•
        current_dir = os.getcwd()
        os.chdir(work_dir)
        print(f"ğŸ”„ [INTERACTIVE] ä» {current_dir} åˆ‡æ¢åˆ°å·¥ä½œç›®å½•: {work_dir}")
        
        try:
            from valve_model_generator import parse_valve_info
            
            # åˆ›å»ºå‹å·ç¼–ç ç›®å½•
            os.makedirs("å‹å·ç¼–ç åçš„è¯¢ä»·è¡¨æ•°æ®", exist_ok=True)
            
            # è¯»å–åŸå§‹è¯¢ä»·è¡¨
            csv_path = os.path.join("è§„èŒƒåå®¢æˆ·è¯¢ä»·è¡¨æ•°æ®", batch_data['csv_file'])
            df = safe_read_csv(csv_path)
            
            # ç”Ÿæˆå‹å·åˆ—
            models = []
            for index, row in df.iterrows():
                if pd.isna(row['å“å']) or row['å“å'] == 'åˆè®¡':
                    models.append('')
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦äº¤äº’çš„äº§å“
                item_key = f"item_{index}"
                if item_key in batch_data['user_selections']:
                    # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å‚æ•°
                    print(f"ğŸ”§ [INTERACTIVE] ä½¿ç”¨ç”¨æˆ·é€‰æ‹©ç”Ÿæˆå‹å·: ç¬¬{index+1}è¡Œ")
                    
                    # è·å–åŸºç¡€é˜€é—¨ä¿¡æ¯
                    for item in batch_data['incomplete_items']:
                        if item['index'] == index:
                            valve_info = item['valve_info'].copy()
                            user_selections = batch_data['user_selections'][item_key]
                            
                            # åº”ç”¨ç”¨æˆ·é€‰æ‹©
                            valve_info.update(user_selections)
                            
                            # ç”Ÿæˆå‹å·
                            model = generate_model_from_valve_info(valve_info)
                            models.append(model)
                            print(f"âœ… [INTERACTIVE] ç”Ÿæˆå‹å·: {model}")
                            break
                    else:
                        # æ‰¾ä¸åˆ°å¯¹åº”çš„é¡¹ç›®ï¼Œä½¿ç”¨é»˜è®¤æ–¹å¼
                        model = parse_valve_info(row['å“å'], row['è§„æ ¼å‹å·'], username, True)
                        models.append(model)
                else:
                    # ä½¿ç”¨é»˜è®¤æ–¹å¼ç”Ÿæˆå‹å·
                    model = parse_valve_info(row['å“å'], row['è§„æ ¼å‹å·'], username, True)
                    models.append(model)
            
            # æ·»åŠ å‹å·åˆ—
            df['æ ‡å‡†å‹å·'] = models
            
            # ä¿å­˜å‹å·ç¼–ç åçš„æ–‡ä»¶
            output_file = os.path.join("å‹å·ç¼–ç åçš„è¯¢ä»·è¡¨æ•°æ®", batch_data['csv_file'])
            safe_to_csv(df, output_file)
            
            print(f"âœ… [INTERACTIVE] å‹å·ç”Ÿæˆå®Œæˆï¼Œä¿å­˜åˆ°: {output_file}")
            
            # ç»§ç»­åç»­çš„æŠ¥ä»·ç”Ÿæˆæµç¨‹
            # å¤„ç†ä»·æ ¼å¯¹ç…§è¡¨
            price_file = batch_data['price_file']
            # ä½¿ç”¨ç»å¯¹è·¯å¾„
            price_path = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨", price_file)
            
            os.makedirs("è§„èŒƒåçš„ä»·æ ¼å¯¹ç…§è¡¨æ•°æ®", exist_ok=True)
            price_csv_path = os.path.join("è§„èŒƒåçš„ä»·æ ¼å¯¹ç…§è¡¨æ•°æ®", "ä»·æ ¼.csv")
            
            if price_file.endswith('.csv'):
                price_df = safe_read_csv(price_path)
            else:
                price_df = pd.read_excel(price_path)
            
            # æ£€æŸ¥å’Œæ˜ å°„ä»·æ ¼è¡¨åˆ—å
            required_columns = ['å‹å·', 'è§„æ ¼', 'å“ç‰Œ', 'ä»·æ ¼']
            column_mapping = {}
            for col in price_df.columns:
                col_lower = str(col).lower()
                if 'å‹å·' in col_lower:
                    column_mapping[col] = 'å‹å·'
                elif 'è§„æ ¼' in col_lower or 'dn' in col_lower:
                    column_mapping[col] = 'è§„æ ¼'
                elif 'å“ç‰Œ' in col_lower:
                    column_mapping[col] = 'å“ç‰Œ'
                elif 'ä»·æ ¼' in col_lower or 'å•ä»·' in col_lower:
                    column_mapping[col] = 'ä»·æ ¼'
            
            if column_mapping:
                price_df = price_df.rename(columns=column_mapping)
            
            price_df.to_csv(price_csv_path, index=False, encoding='utf-8-sig')
            
            # ç”ŸæˆæŠ¥ä»·
            from generate_quotes import process_inquiry_file, generate_summary_report
            
            os.makedirs("æŠ¥ä»·æ•°æ®", exist_ok=True)
            
            processed_files = []
            output_file = process_inquiry_file(output_file, price_df)
            if output_file:
                processed_files.append(output_file)
            
            # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
            if processed_files:
                generate_summary_report(processed_files)
            
            # å¤åˆ¶ç”Ÿæˆçš„æŠ¥ä»·åˆ°ç”¨æˆ·æŠ¥ä»·ç›®å½•
            quote_dir = os.path.join(DATA_ROOT, username, "æŠ¥ä»·å•")
            os.makedirs(quote_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            generated_files = []
            
            if os.path.exists("æŠ¥ä»·æ•°æ®"):
                for file in os.listdir("æŠ¥ä»·æ•°æ®"):
                    if file.endswith(('.xlsx', '.csv')):
                        src = os.path.join("æŠ¥ä»·æ•°æ®", file)
                        dst = os.path.join(quote_dir, f"{timestamp}_äº¤äº’å¼_{file}")
                        shutil.copy2(src, dst)
                        generated_files.append(f"{timestamp}_äº¤äº’å¼_{file}")
            
            print(f"ğŸ‰ [INTERACTIVE] äº¤äº’å¼æŠ¥ä»·å®Œæˆï¼Œç”Ÿæˆæ–‡ä»¶: {generated_files}")
            
            return {
                "message": "äº¤äº’å¼æŠ¥ä»·å•ç”ŸæˆæˆåŠŸ",
                "files": generated_files,
                "total_interactions": len(batch_data['user_selections'])
            }
            
        finally:
            # è¿”å›åŸç›®å½•å¹¶æ¸…ç†
            try:
                os.chdir(original_dir)
                print(f"ğŸ”„ [INTERACTIVE] è¿”å›åŸå§‹ç›®å½•: {original_dir}")
            except Exception as e:
                # å¦‚æœæ— æ³•è¿”å›åŸå§‹ç›®å½•ï¼Œå°è¯•åˆ‡æ¢åˆ°è„šæœ¬ç›®å½•
                script_dir = os.path.dirname(os.path.abspath(__file__))
                try:
                    os.chdir(script_dir)
                    print(f"ğŸ”„ [INTERACTIVE] æ— æ³•è¿”å›åŸå§‹ç›®å½•ï¼Œåˆ‡æ¢åˆ°è„šæœ¬ç›®å½•: {script_dir}")
                except Exception:
                    print(f"âš ï¸  [INTERACTIVE] æ— æ³•åˆ‡æ¢åˆ°ä»»ä½•æœ‰æ•ˆç›®å½•")
            
            try:
                if os.path.exists(work_dir):
                    shutil.rmtree(work_dir)
                    print(f"ğŸ—‘ï¸  [INTERACTIVE] æ¸…ç†ä¸´æ—¶ç›®å½•: {work_dir}")
            except Exception as e:
                print(f"âš ï¸  [INTERACTIVE] æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
            
            # æ¸…ç†æ‰¹æ¬¡æ•°æ®
            if batch_id in interactive_batches:
                del interactive_batches[batch_id]
                print(f"ğŸ—‘ï¸  [INTERACTIVE] æ¸…ç†æ‰¹æ¬¡æ•°æ®: {batch_id}")
            
    except Exception as e:
        print(f"âŒ [INTERACTIVE] å®Œæˆäº¤äº’å¼æŠ¥ä»·å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å®Œæˆäº¤äº’å¼æŠ¥ä»·å¤±è´¥: {str(e)}")

def generate_model_from_valve_info(valve_info):
    """æ ¹æ®é˜€é—¨ä¿¡æ¯ç”Ÿæˆå‹å·"""
    valve_type = valve_info.get('product_type', '')
    drive_mode = valve_info.get('drive_mode', '')
    connection = valve_info.get('connection', '')
    structure = valve_info.get('structure', '')
    sealing = valve_info.get('sealing', '')
    pressure = valve_info.get('pressure', '16')
    material = valve_info.get('material', 'Q')
    
    # å¯¹äºç‰¹æ®Šäº§å“ï¼Œç›´æ¥è¿”å›å®Œæ•´å‹å·
    if valve_type in ['100X', '200X', '500X', '800X']:
        model = ""
        if connection == '8':
            model = "8"
        model += valve_type + f"-{pressure}{material}"
        return model
    
    # ç»„åˆæ ‡å‡†å‹å·
    model = valve_type
    
    # é©±åŠ¨æ–¹å¼ï¼ˆæ‰‹åŠ¨é»˜è®¤ä¸æ ‡ï¼‰
    if drive_mode:
        model += drive_mode
    
    # è¿æ¥æ–¹å¼
    model += connection
    
    # ç»“æ„å½¢å¼
    model += structure
    
    # å¯†å°ææ–™
    model += sealing
    
    # å‹åŠ›-ææ–™
    model += f"-{pressure}{material}"
    
    return model

def read_csv_with_encoding_fallback(file_bytes):
    import pandas as pd
    import io
    try:
        return pd.read_csv(io.BytesIO(file_bytes))
    except UnicodeDecodeError:
        try:
            return pd.read_csv(io.BytesIO(file_bytes), encoding='gbk')
        except Exception as e:
            raise e

# æ–‡ä»¶è§£æä¸º Excel çš„å·¥å…·å‡½æ•°
def parse_file_to_excel(file_bytes, filename, save_dir):
    import pandas as pd
    import os
    ext = os.path.splitext(filename)[-1].lower()
    excel_name = os.path.splitext(filename)[0] + ".xlsx"
    save_path = os.path.join(save_dir, excel_name)
    df = None

    print(f"ğŸ” [PARSE] å¼€å§‹è§£ææ–‡ä»¶: {filename}, æ‰©å±•å: {ext}")

    try:
        if ext in [".csv"]:
            print(f"ğŸ“Š [PARSE] è§£æCSVæ–‡ä»¶")
            df = read_csv_with_encoding_fallback(file_bytes)
        elif ext in [".xlsx", ".xls"]:
            print(f"ğŸ“Š [PARSE] è§£æExcelæ–‡ä»¶")
            df = pd.read_excel(io.BytesIO(file_bytes))
        elif ext == ".pdf":
            print(f"ğŸ“Š [PARSE] è§£æPDFæ–‡ä»¶")
            with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    print(f"ğŸ“„ [PARSE] å¤„ç†PDFç¬¬{page_num+1}é¡µ")
                    table = page.extract_table()
                    if table:
                        df = pd.DataFrame(table[1:], columns=table[0])
                        print(f"âœ… [PARSE] PDFç¬¬{page_num+1}é¡µæ‰¾åˆ°è¡¨æ ¼ï¼Œå…±{len(df)}è¡Œ")
                        break
            if df is None:
                raise Exception("PDFæœªæ£€æµ‹åˆ°è¡¨æ ¼")
        elif ext == ".docx":
            print(f"ğŸ“Š [PARSE] è§£æWordæ–‡ä»¶")
            doc = Document(io.BytesIO(file_bytes))
            print(f"ğŸ“„ [PARSE] Wordæ–‡æ¡£åŒ…å«{len(doc.tables)}ä¸ªè¡¨æ ¼")
            for table_num, table in enumerate(doc.tables):
                print(f"ğŸ“‹ [PARSE] å¤„ç†Wordç¬¬{table_num+1}ä¸ªè¡¨æ ¼")
                data = [[cell.text for cell in row.cells] for row in table.rows]
                if data and len(data) > 1:  # ç¡®ä¿æœ‰è¡¨å¤´å’Œæ•°æ®
                    df = pd.DataFrame(data[1:], columns=data[0])
                    print(f"âœ… [PARSE] Wordç¬¬{table_num+1}ä¸ªè¡¨æ ¼è§£ææˆåŠŸï¼Œå…±{len(df)}è¡Œ")
                    break
            if df is None:
                raise Exception("Wordæœªæ£€æµ‹åˆ°æœ‰æ•ˆè¡¨æ ¼")
        elif ext in [".png", ".jpg", ".jpeg", ".bmp", ".tiff"]:
            print(f"ğŸ“Š [PARSE] è§£æå›¾ç‰‡æ–‡ä»¶")
            image = Image.open(io.BytesIO(file_bytes))
            print(f"ğŸ–¼ï¸ [PARSE] å›¾ç‰‡å°ºå¯¸: {image.size}")
            
            # ä½¿ç”¨OCRæå–æ–‡æœ¬
            try:
                text = pytesseract.image_to_string(
                    image,
                    lang='eng'
                )
                print(f"ğŸ“ [PARSE] OCRæå–æ–‡æœ¬é•¿åº¦: {len(text)}")
                print(f"ğŸ“ [PARSE] OCRæå–æ–‡æœ¬é¢„è§ˆ: {text[:200]}...")
                
                if not text.strip():
                    raise Exception("å›¾ç‰‡æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ–‡æœ¬å†…å®¹")
                
                # ä½¿ç”¨OCRä¿®æ­£å™¨å¤„ç†æ–‡æœ¬
                corrector = OCRCorrector()
                results = corrector.process_ocr_text(text)
                
                # åˆ›å»ºæ•°æ®æ¡†
                excel_data = []
                for item in results['extracted_data']:
                    excel_data.append({
                        'å“å': f"é˜€é—¨ DN{item['dn_value']}",
                        'è§„æ ¼å‹å·': f"DN{item['dn_value']}",
                        'æ•°é‡': item['quantity'],
                        'å•ä½': 'ä¸ª',
                        'åŸå§‹æ–‡æœ¬': item['original_text'],
                        'ä¿®æ­£æ–‡æœ¬': item['corrected_text'],
                        'ç½®ä¿¡åº¦': item['confidence']
                    })
                
                # å¦‚æœæ²¡æœ‰æå–åˆ°æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«åŸå§‹æ–‡æœ¬çš„è¡Œ
                if not excel_data:
                    excel_data.append({
                        'å“å': 'OCRæå–æ–‡æœ¬',
                        'è§„æ ¼å‹å·': 'åŸå§‹æ–‡æœ¬',
                        'æ•°é‡': '1',
                        'å•ä½': 'ä¸ª',
                        'åŸå§‹æ–‡æœ¬': text,
                        'ä¿®æ­£æ–‡æœ¬': results['corrected_text'],
                        'ç½®ä¿¡åº¦': 'low'
                    })
                
                df = pd.DataFrame(excel_data)
                print(f"âœ… [PARSE] å›¾ç‰‡OCRå¤„ç†å®Œæˆï¼Œç”Ÿæˆ{len(df)}è¡Œæ•°æ®")
                
            except Exception as ocr_error:
                print(f"âŒ [PARSE] OCRå¤„ç†å¤±è´¥: {ocr_error}")
                # å¦‚æœOCRå¤±è´¥ï¼Œå°è¯•ç®€å•çš„æ–‡æœ¬åˆ†å‰²
                lines = [line.split() for line in text.splitlines() if line.strip()]
                if not lines:
                    raise Exception("å›¾ç‰‡æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ–‡æœ¬å†…å®¹")
                if len(set(len(row) for row in lines)) != 1:
                    print(f"âš ï¸ [PARSE] å›¾ç‰‡è¡¨æ ¼ç»“æ„ä¸è§„æ•´ï¼Œä½¿ç”¨ç®€å•åˆ†å‰²")
                    # åˆ›å»ºç®€å•çš„æ•°æ®æ¡†
                    df = pd.DataFrame({
                        'åŸå§‹æ–‡æœ¬': [text],
                        'å¤„ç†çŠ¶æ€': ['OCRå¤„ç†å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥']
                    })
                else:
                    df = pd.DataFrame(lines)
        else:
            raise Exception(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}")

        if df is None:
            raise Exception("æ–‡ä»¶è§£æå¤±è´¥ï¼Œæœªç”Ÿæˆæœ‰æ•ˆæ•°æ®")

        print(f"ğŸ’¾ [PARSE] ä¿å­˜Excelæ–‡ä»¶: {save_path}")
        df.to_excel(save_path, index=False)
        print(f"âœ… [PARSE] æ–‡ä»¶è§£æå®Œæˆ: {excel_name}")
        return excel_name

    except Exception as e:
        print(f"âŒ [PARSE] æ–‡ä»¶è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise e

# ä¿®æ”¹ä¸Šä¼ æ¥å£ï¼Œè‡ªåŠ¨è½¬ä¸º Excel
@app.post("/api/upload/price", response_model=PriceUploadResponse, summary="ä¸Šä¼ ä»·æ ¼è¡¨", tags=["upload"], description="ä¸Šä¼ ä¸€ä¸ª Excel ä»·æ ¼è¡¨ï¼ŒéªŒè¯åˆ—æ ¼å¼å¹¶ä¿å­˜ï¼ˆä¼šæ›¿æ¢æ—§ä»·æ ¼è¡¨ï¼‰ã€‚")
async def upload_price_table(file: UploadFile = File(...), username: str = Depends(verify_credentials)):
    try:
        print(f"ğŸ“¤ [UPLOAD] å¼€å§‹ä¸Šä¼ ä»·æ ¼è¡¨: {file.filename}")
        
        # æ£€æŸ¥æ–‡ä»¶
        if not file.filename:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if not file.filename.endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒExcelæ–‡ä»¶æ ¼å¼(.xlsx, .xls)")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_bytes = await file.read()
        if len(file_bytes) == 0:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹ä¸ºç©º")
        
        print(f"ğŸ“Š [UPLOAD] æ–‡ä»¶å¤§å°: {len(file_bytes)} å­—èŠ‚")
        
        # ä¸´æ—¶ä¿å­˜æ–‡ä»¶è¿›è¡ŒéªŒè¯
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_file:
            temp_file.write(file_bytes)
            temp_path = temp_file.name
        
        try:
            # è¯»å–Excelæ–‡ä»¶è¿›è¡ŒéªŒè¯
            import pandas as pd
            df = pd.read_excel(temp_path)
            
            # å¯¼å…¥éªŒè¯æ¨¡å—
            from price_validator import validate_price_table_format
            
            # éªŒè¯ä»·æ ¼è¡¨æ ¼å¼
            validation_result = validate_price_table_format(df)
            
            if not validation_result['is_valid']:
                # éªŒè¯å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                error_message = "ä»·æ ¼è¡¨æ ¼å¼éªŒè¯å¤±è´¥:\n" + "\n".join(validation_result['errors'])
                raise HTTPException(status_code=400, detail=error_message)
            
            # éªŒè¯æˆåŠŸï¼Œæ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²æœ‰ä»·æ ¼è¡¨
            user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
            os.makedirs(user_dir, exist_ok=True)
            print(f"ğŸ“ [UPLOAD] ç”¨æˆ·ç›®å½•: {user_dir}")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»·æ ¼è¡¨æ–‡ä»¶
            existing_files = [f for f in os.listdir(user_dir) if f.endswith(('.xlsx', '.xls', '.csv'))]
            if existing_files:
                # åˆ é™¤ç°æœ‰ä»·æ ¼è¡¨æ–‡ä»¶
                for existing_file in existing_files:
                    existing_path = os.path.join(user_dir, existing_file)
                    try:
                        os.remove(existing_path)
                        print(f"ğŸ—‘ï¸ [UPLOAD] åˆ é™¤ç°æœ‰ä»·æ ¼è¡¨: {existing_file}")
                    except Exception as e:
                        print(f"âš ï¸ [UPLOAD] åˆ é™¤ç°æœ‰æ–‡ä»¶å¤±è´¥: {e}")
            
            # è§£ææ–‡ä»¶
            try:
                excel_name = parse_file_to_excel(file_bytes, file.filename, user_dir)
                print(f"âœ… [UPLOAD] ä»·æ ¼è¡¨ä¸Šä¼ æˆåŠŸ: {excel_name}")
                
                # è¿”å›æˆåŠŸä¿¡æ¯å’Œå“ç‰Œåˆ—è¡¨
                return {
                    "message": validation_result['message'] + " (å·²æ›¿æ¢åŸæœ‰ä»·æ ¼è¡¨)",
                    "brands": validation_result['brands'],
                    "filename": excel_name
                }
            except Exception as parse_error:
                print(f"âŒ [UPLOAD] æ–‡ä»¶è§£æå¤±è´¥: {parse_error}")
                import traceback
                traceback.print_exc()
                raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è§£æå¤±è´¥: {str(parse_error)}")
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.unlink(temp_path)
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [UPLOAD] ä»·æ ¼è¡¨ä¸Šä¼ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.post("/api/upload/inquiry", response_model=UploadResponse, summary="ä¸Šä¼ è¯¢ä»·è¡¨", tags=["upload"], description="ä¸Šä¼ ä»»æ„æ”¯æŒæ ¼å¼çš„è¯¢ä»·è¡¨æ–‡ä»¶ï¼Œè§£æå¹¶è§„èŒƒä¸º Excelã€‚")
async def upload_inquiry_table(file: UploadFile = File(...), username: str = Depends(verify_credentials)):
    try:
        print(f"ğŸ“¤ [UPLOAD] å¼€å§‹ä¸Šä¼ è¯¢ä»·è¡¨: {file.filename}")
        
        # æ£€æŸ¥æ–‡ä»¶
        if not file.filename:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_bytes = await file.read()
        if len(file_bytes) == 0:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹ä¸ºç©º")
        
        print(f"ğŸ“Š [UPLOAD] æ–‡ä»¶å¤§å°: {len(file_bytes)} å­—èŠ‚")
        
        # åˆ›å»ºç”¨æˆ·ç›®å½•
        user_dir = os.path.join(DATA_ROOT, username, "è¯¢ä»·è¡¨")
        os.makedirs(user_dir, exist_ok=True)
        print(f"ğŸ“ [UPLOAD] ç”¨æˆ·ç›®å½•: {user_dir}")
        
        # è§£ææ–‡ä»¶
        try:
            excel_name = parse_file_to_excel(file_bytes, file.filename, user_dir)
            print(f"âœ… [UPLOAD] è¯¢ä»·è¡¨ä¸Šä¼ æˆåŠŸ: {excel_name}")
            return {"message": "è¯¢ä»·è¡¨ä¸Šä¼ å¹¶è§£ææˆåŠŸ", "filename": excel_name}
        except Exception as parse_error:
            print(f"âŒ [UPLOAD] æ–‡ä»¶è§£æå¤±è´¥: {parse_error}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è§£æå¤±è´¥: {str(parse_error)}")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [UPLOAD] è¯¢ä»·è¡¨ä¸Šä¼ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.post("/api/ocr/process-image", response_model=OCRProcessResponse, summary="å›¾ç‰‡ OCR è¯†åˆ«ä¸çº é”™", tags=["ocr"], description="ä¸Šä¼ å›¾ç‰‡æ‰§è¡Œ OCR è¯†åˆ«å¹¶å¯¹æ–‡æœ¬è¿›è¡Œç»“æ„åŒ–è§£æä¸çº é”™ã€‚")
async def process_image_ocr(file: UploadFile = File(...), username: str = Depends(verify_credentials)):
    try:
        print(f"ğŸ” [OCR] å¼€å§‹å¤„ç†å›¾ç‰‡OCR: {file.filename}")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.filename or not file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶æ ¼å¼")
        
        # è¯»å–å›¾ç‰‡æ–‡ä»¶
        file_bytes = await file.read()
        
        # ä½¿ç”¨OCRæå–æ–‡æœ¬
        try:
            image = Image.open(io.BytesIO(file_bytes))
            text = pytesseract.image_to_string(
                image,
                lang='eng'
            )
            print(f"ğŸ“ [OCR] åŸå§‹æå–æ–‡æœ¬: {text[:200]}...")
        except Exception as ocr_error:
            print(f"âŒ [OCR] OCRæå–å¤±è´¥: {ocr_error}")
            raise HTTPException(status_code=500, detail=f"OCRæ–‡æœ¬æå–å¤±è´¥: {str(ocr_error)}")
        
        # ä½¿ç”¨OCRä¿®æ­£å™¨å¤„ç†æ–‡æœ¬
        corrector = OCRCorrector()
        results = corrector.process_ocr_text(text)
        
        print(f"âœ… [OCR] OCRå¤„ç†å®Œæˆ:")
        print(f"   åŸå§‹æ–‡æœ¬è¡Œæ•°: {results['statistics']['original_lines']}")
        print(f"   ä¿®æ­£å­—ç¬¦æ•°: {results['statistics']['corrections_made']}")
        print(f"   æå–é¡¹ç›®æ•°: {results['statistics']['extracted_items']}")
        
        return {
            "message": "å›¾ç‰‡OCRå¤„ç†æˆåŠŸ",
            "original_text": text,
            "corrected_text": results['corrected_text'],
            "extracted_data": results['extracted_data'],
            "statistics": results['statistics']
        }
        
    except Exception as e:
        print(f"âŒ [OCR] å›¾ç‰‡OCRå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å›¾ç‰‡OCRå¤„ç†å¤±è´¥: {str(e)}")

@app.post("/api/ocr/process-image-to-excel", summary="å›¾ç‰‡ OCR ç”Ÿæˆè¯¢ä»· Excel", tags=["ocr"], description="å¯¹å›¾ç‰‡æ‰§è¡Œ OCR å¹¶ç›´æ¥ç”Ÿæˆæ ‡å‡†ç»“æ„çš„è¯¢ä»· Excel æ–‡ä»¶å­˜å…¥ç”¨æˆ·ç›®å½•ã€‚")
async def process_image_to_excel(file: UploadFile = File(...), username: str = Depends(verify_credentials)):
    try:
        print(f"ğŸ” [OCR] å¼€å§‹å¤„ç†å›¾ç‰‡OCRå¹¶ç”ŸæˆExcel: {file.filename}")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.filename or not file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶æ ¼å¼")
        
        # è¯»å–å›¾ç‰‡æ–‡ä»¶
        file_bytes = await file.read()
        
        # ä½¿ç”¨OCRæå–æ–‡æœ¬
        try:
            image = Image.open(io.BytesIO(file_bytes))
            text = pytesseract.image_to_string(
                image,
                lang='eng'
            )
            print(f"ğŸ“ [OCR] åŸå§‹æå–æ–‡æœ¬: {text[:200]}...")
        except Exception as ocr_error:
            print(f"âŒ [OCR] OCRæå–å¤±è´¥: {ocr_error}")
            raise HTTPException(status_code=500, detail=f"OCRæ–‡æœ¬æå–å¤±è´¥: {str(ocr_error)}")
        
        # ä½¿ç”¨OCRä¿®æ­£å™¨å¤„ç†æ–‡æœ¬
        corrector = OCRCorrector()
        results = corrector.process_ocr_text(text)
        
        # ç”ŸæˆExcelæ–‡ä»¶
        import pandas as pd
        from datetime import datetime
        
        # åˆ›å»ºæ•°æ®æ¡†
        excel_data = []
        for item in results['extracted_data']:
            excel_data.append({
                'å“å': f"é˜€é—¨ DN{item['dn_value']}",
                'è§„æ ¼å‹å·': f"DN{item['dn_value']}",
                'æ•°é‡': item['quantity'],
                'å•ä½': 'ä¸ª',
                'åŸå§‹æ–‡æœ¬': item['original_text'],
                'ä¿®æ­£æ–‡æœ¬': item['corrected_text'],
                'ç½®ä¿¡åº¦': item['confidence']
            })
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«åŸå§‹æ–‡æœ¬çš„è¡Œ
        if not excel_data:
            excel_data.append({
                'å“å': 'OCRæå–æ–‡æœ¬',
                'è§„æ ¼å‹å·': 'åŸå§‹æ–‡æœ¬',
                'æ•°é‡': '1',
                'å•ä½': 'ä¸ª',
                'åŸå§‹æ–‡æœ¬': text,
                'ä¿®æ­£æ–‡æœ¬': results['corrected_text'],
                'ç½®ä¿¡åº¦': 'low'
            })
        
        df = pd.DataFrame(excel_data)
        
        # ä¿å­˜åˆ°ç”¨æˆ·ç›®å½•
        user_dir = os.path.join(DATA_ROOT, username, "è¯¢ä»·è¡¨")
        os.makedirs(user_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        excel_filename = f"OCR_{timestamp}_{Path(file.filename).stem}.xlsx"
        excel_path = os.path.join(user_dir, excel_filename)
        
        df.to_excel(excel_path, index=False)
        
        print(f"âœ… [OCR] Excelæ–‡ä»¶ç”ŸæˆæˆåŠŸ: {excel_filename}")
        
        return {
            "message": "å›¾ç‰‡OCRå¤„ç†å¹¶ç”ŸæˆExcelæˆåŠŸ",
            "filename": excel_filename,
            "original_text": text,
            "corrected_text": results['corrected_text'],
            "extracted_data": results['extracted_data'],
            "statistics": results['statistics']
        }
        
    except Exception as e:
        print(f"âŒ [OCR] å›¾ç‰‡OCRå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å›¾ç‰‡OCRå¤„ç†å¤±è´¥: {str(e)}")

@app.get("/api/files", response_model=FileListResponse, summary="åˆ—å‡ºç”¨æˆ·æ–‡ä»¶", tags=["files"], description="åˆ—å‡ºå½“å‰ç”¨æˆ·ä¸Šä¼ çš„ä»·æ ¼è¡¨ã€è¯¢ä»·è¡¨ä»¥åŠç”Ÿæˆçš„æŠ¥ä»·å•æ–‡ä»¶åã€‚")
async def list_files(username: str = Depends(verify_credentials)):
    print(f"ğŸ“‚ è·å–æ–‡ä»¶åˆ—è¡¨è¯·æ±‚: username={username}")
    
    user_dir = os.path.join(DATA_ROOT, username)
    files = {
        "price_tables": [],
        "inquiry_tables": [],
        "quotes": []
    }
    
    # ä»·æ ¼è¡¨
    price_dir = os.path.join(user_dir, "ä»·æ ¼è¡¨")
    if os.path.exists(price_dir):
        price_files = []
        for f in os.listdir(price_dir):
            if f.endswith(('.xlsx', '.xls', '.csv')):
                file_path = os.path.join(price_dir, f)
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    price_files.append(f)
        files["price_tables"] = sorted(price_files, key=lambda x: os.path.getmtime(os.path.join(price_dir, x)), reverse=True)
        print(f"ğŸ“‹ ä»·æ ¼è¡¨æ–‡ä»¶ ({len(price_files)}ä¸ª): {price_files}")
    
    # è¯¢ä»·è¡¨
    inquiry_dir = os.path.join(user_dir, "è¯¢ä»·è¡¨")
    if os.path.exists(inquiry_dir):
        inquiry_files = []
        for f in os.listdir(inquiry_dir):
            if f.endswith(('.xlsx', '.xls', '.csv')):
                file_path = os.path.join(inquiry_dir, f)
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    inquiry_files.append(f)
        files["inquiry_tables"] = sorted(inquiry_files, key=lambda x: os.path.getmtime(os.path.join(inquiry_dir, x)), reverse=True)
        print(f"ğŸ“‹ è¯¢ä»·è¡¨æ–‡ä»¶ ({len(inquiry_files)}ä¸ª): {inquiry_files}")
    
    # æŠ¥ä»·å•
    quote_dir = os.path.join(user_dir, "æŠ¥ä»·å•")
    if os.path.exists(quote_dir):
        quote_files = []
        for f in os.listdir(quote_dir):
            if f.endswith(('.xlsx', '.csv')):
                file_path = os.path.join(quote_dir, f)
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    quote_files.append(f)
        files["quotes"] = sorted(quote_files, key=lambda x: os.path.getmtime(os.path.join(quote_dir, x)), reverse=True)
        print(f"ğŸ“‹ æŠ¥ä»·å•æ–‡ä»¶ ({len(quote_files)}ä¸ª): {quote_files}")
    else:
        print(f"âŒ æŠ¥ä»·å•ç›®å½•ä¸å­˜åœ¨: {quote_dir}")
    
    print(f"ğŸ“Š è¿”å›æ–‡ä»¶åˆ—è¡¨: {files}")
    return files

def append_quote_to_original(price_file, inquiry_file, output_file, price_columns=None):
    """
    åªåœ¨åŸå§‹è¡¨æ ¼åè¿½åŠ "æ ‡å‡†å‹å·ã€ä»·æ ¼ã€å“ç‰Œã€æ€»ä»·"4åˆ—ï¼ŒåŸå†…å®¹å’Œæ ¼å¼å…¨éƒ¨ä¿ç•™ã€‚
    è‡ªåŠ¨è¯†åˆ«ä»·æ ¼è¡¨çš„äº§å“åç§°ã€å‹å·ã€è§„æ ¼å­—æ®µï¼Œæå‡å…¼å®¹æ€§ã€‚
    """
    orig_df = pd.read_excel(inquiry_file)
    price_df = pd.read_excel(price_file)
    if price_columns:
        price_df = price_df.rename(columns=price_columns)
    orig_df['æ ‡å‡†å‹å·'] = ''
    orig_df['ä»·æ ¼'] = ''
    orig_df['å“ç‰Œ'] = ''
    orig_df['æ€»ä»·'] = ''

    # è‡ªåŠ¨è¯†åˆ«ä»·æ ¼è¡¨çš„äº§å“åç§°åˆ—
    product_name_col = None
    for col in ['äº§å“åç§°', 'åç§°', 'å“å', 'é¡¹ç›®åç§°', 'ç‰©æ–™åç§°']:
        if col in price_df.columns:
            product_name_col = col
            break
    if not product_name_col:
        raise Exception("ä»·æ ¼è¡¨ç¼ºå°‘äº§å“åç§°ç›¸å…³åˆ—")

    # è‡ªåŠ¨è¯†åˆ«ä»·æ ¼è¡¨çš„å‹å·åˆ—
    model_col = None
    for col in ['å‹å·', 'äº§å“å‹å·', 'è§„æ ¼å‹å·', 'å‹å·ç¼–ç ']:
        if col in price_df.columns:
            model_col = col
            break
    # å‹å·åˆ—å¯é€‰

    # è‡ªåŠ¨è¯†åˆ«ä»·æ ¼è¡¨çš„è§„æ ¼åˆ—
    spec_col = None
    for col in ['è§„æ ¼', 'è§„æ ¼å‹å·', 'å£å¾„', 'å…¬ç§°ç›´å¾„']:
        if col in price_df.columns:
            spec_col = col
            break
    # è§„æ ¼åˆ—å¯é€‰

    # è‡ªåŠ¨è¯†åˆ«å“ç‰Œåˆ—
    brand_col = None
    for col in ['å“ç‰Œ', 'å‚å•†', 'ç”Ÿäº§å‚å®¶']:
        if col in price_df.columns:
            brand_col = col
            break

    for idx, row in orig_df.iterrows():
        name = row.get('åç§°', '')
        spec = row.get('è§„æ ¼') or row.get('è§„æ ¼å‹å·') or ''
        # ç”Ÿæˆæ ‡å‡†å‹å·
        orig_df.at[idx, 'æ ‡å‡†å‹å·'] = parse_valve_info(name, spec)
        # åŒ¹é…ä»·æ ¼è¡¨
        if spec_col:
            match = price_df[
                (price_df[product_name_col] == name) &
                (price_df[spec_col] == spec)
            ]
        else:
            match = price_df[
                (price_df[product_name_col] == name)
            ]
        if not match.empty:
            orig_df.at[idx, 'ä»·æ ¼'] = match.iloc[0].get('å•ä»·', '')
            if brand_col:
                orig_df.at[idx, 'å“ç‰Œ'] = match.iloc[0].get(brand_col, '')
            try:
                qty = float(row.get('æ•°é‡', 1))
                orig_df.at[idx, 'æ€»ä»·'] = float(match.iloc[0].get('å•ä»·', 0)) * qty
            except Exception:
                orig_df.at[idx, 'æ€»ä»·'] = ''
        else:
            orig_df.at[idx, 'ä»·æ ¼'] = ''
            orig_df.at[idx, 'å“ç‰Œ'] = ''
            orig_df.at[idx, 'æ€»ä»·'] = ''
    orig_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    return output_file

@app.get("/api/get-brands")
async def get_brands(price_file: str = Query(...), username: str = Depends(verify_credentials)):
    """è·å–ä»·æ ¼è¡¨ä¸­çš„å“ç‰Œåˆ—è¡¨"""
    try:
        print(f"ğŸ” [BRANDS] å¼€å§‹è·å–å“ç‰Œåˆ—è¡¨")
        print(f"ğŸ“ [BRANDS] ç”¨æˆ·: {username}")
        print(f"ğŸ’° [BRANDS] ä»·æ ¼æ–‡ä»¶: {price_file}")
        
        user_dir = os.path.join(DATA_ROOT, username)
        price_path = os.path.join(user_dir, "ä»·æ ¼è¡¨", price_file)
        
        if not os.path.exists(price_path):
            raise HTTPException(status_code=404, detail=f"ä»·æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {price_file}")
        
        # å¯¼å…¥å“ç‰Œæå–å‡½æ•°
        from price_validator import extract_brands_from_price_table
        
        # æå–å“ç‰Œåˆ—è¡¨
        brands = extract_brands_from_price_table(price_path)
        
        print(f"âœ… [BRANDS] æˆåŠŸæå–å“ç‰Œ: {brands}")
        return {"brands": brands}
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [BRANDS] è·å–å“ç‰Œåˆ—è¡¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"è·å–å“ç‰Œåˆ—è¡¨å¤±è´¥: {str(e)}")

@app.post("/api/generate-quote")
async def generate_quote(
    price_file: str = Form(...),
    inquiry_file: str = Form(...),
    company: str = Form(...),  # æ¥æ”¶å‰ç«¯æ¨æ–­çš„å…¬å¸å
    brand: str = Form(None),   # æ–°å¢ï¼Œå‰ç«¯ä¼ é€’çš„å“ç‰Œ
    scheme: str = Form("scheme1"),  # æ–¹æ¡ˆé€‰æ‹©ï¼šscheme1=ç¬¬ä¸€ç§ï¼Œscheme2=ç¬¬äºŒç§
    username: str = Depends(verify_credentials),
    auto_fill_price: bool = Form(False),  # æ–°å¢å‚æ•°ï¼Œæ˜¯å¦è‡ªåŠ¨ç”¨ä»·æ ¼è¡¨å†æ¬¡å¡«å……ä»·æ ¼å’Œå“ç‰Œ
    # ç¬¬äºŒæ–¹æ¡ˆçš„å…¬å¸ä¿¡æ¯å‚æ•°
    company_name: str = Form(None),
    business_contact: str = Form(None),
    contact_phone: str = Form(None),
    contact_email: str = Form(None),
    customer_header: str = Form(None),
    recipient: str = Form(None),
    contact_method: str = Form(None),
    address: str = Form(None),
    tax_rate: str = Form(None)
):
    try:
        print(f"ğŸš€ [QUOTE] å¼€å§‹ç”Ÿæˆä»·æ ¼åçš„æŠ¥ä»·å•")
        print(f"ğŸ“ [QUOTE] ç”¨æˆ·: {username}")
        print(f"ğŸ’° [QUOTE] ä»·æ ¼æ–‡ä»¶: {price_file}")
        print(f"ğŸ“‹ [QUOTE] è¯¢ä»·æ–‡ä»¶: {inquiry_file}")
        print(f"ğŸ¢ [QUOTE] å…¬å¸: {company}")
        print(f"ğŸ·ï¸ [QUOTE] å“ç‰Œ: {brand}")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹ï¼Œå¦‚æœæ˜¯å›¾ç‰‡æˆ–æ–‡æœ¬æ–‡ä»¶ï¼Œå¼ºåˆ¶ä½¿ç”¨ç¬¬äºŒç§æ–¹æ¡ˆ
        file_ext = os.path.splitext(inquiry_file)[-1].lower()
        image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif']
        text_extensions = ['.txt', '.doc', '.docx', '.pdf']
        
        if file_ext in image_extensions or file_ext in text_extensions:
            print(f"ğŸ“¸ [QUOTE] æ£€æµ‹åˆ°å›¾ç‰‡/æ–‡æœ¬æ–‡ä»¶ ({file_ext})ï¼Œå¼ºåˆ¶ä½¿ç”¨ç¬¬äºŒç§æ–¹æ¡ˆ")
            scheme = "scheme2"
        
        user_dir = os.path.join(DATA_ROOT, username)
        price_path = os.path.join(user_dir, "ä»·æ ¼è¡¨", price_file)
        inquiry_path = os.path.join(user_dir, "è¯¢ä»·è¡¨", inquiry_file)
        if not os.path.exists(price_path):
            raise HTTPException(status_code=404, detail=f"ä»·æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {price_file}")
        if not os.path.exists(inquiry_path):
            raise HTTPException(status_code=404, detail=f"è¯¢ä»·æ–‡ä»¶ä¸å­˜åœ¨: {inquiry_file}")
        base_name = os.path.splitext(os.path.basename(inquiry_file))[0]
        quote_dir = os.path.join(user_dir, "æŠ¥ä»·å•")
        os.makedirs(quote_dir, exist_ok=True)
        standard_csv = os.path.join(quote_dir, f"{base_name}_æ ‡å‡†æ ¼å¼.csv")
        standard_xlsx = os.path.join(quote_dir, f"{base_name}_æ ‡å‡†æ ¼å¼.xlsx")
        from convert_excel_to_csv import process_excel_to_standard_csv
        # è®©æ ‡å‡†åŒ–æµç¨‹è¿”å›å®é™…ç”Ÿæˆçš„æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        result = process_excel_to_standard_csv(inquiry_path, None, price_file=price_path, selected_brand=brand)
        if isinstance(result, tuple):
            standard_csv, standard_xlsx = result
            print(f"[DEBUG] å®é™…ç”Ÿæˆçš„CSVæ–‡ä»¶: {standard_csv}")
            print(f"[DEBUG] å®é™…ç”Ÿæˆçš„XLSXæ–‡ä»¶: {standard_xlsx}")
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬è¿”å›å€¼
            standard_csv = result
            standard_xlsx = standard_csv.replace('.csv', '.xlsx')
            print(f"[DEBUG] å®é™…ç”Ÿæˆçš„CSVæ–‡ä»¶: {standard_csv}")
            import pandas as pd
            df = pd.read_csv(standard_csv)
            df.to_excel(standard_xlsx, index=False)
        # è¯»å–æ•°æ®ç”¨äºåç»­å¤„ç†
        import pandas as pd
        df = pd.read_csv(standard_csv)
        print(f"ğŸ“Š [QUOTE] è¯¢ä»·è¡¨æ•°æ®è¯»å–å®Œæˆï¼Œå…±{len(df)}è¡Œ")
        # è¯»å–ç”¨æˆ·æŠ˜æ‰£
        rules_manager = get_rules_manager()
        user_discount = rules_manager.get_user_discount(username)
        print(f"[QUOTE] åº”ç”¨ç”¨æˆ·æŠ˜æ‰£: {user_discount}")

        # æ ¹æ®æ–¹æ¡ˆç”Ÿæˆ
        result_payload = {"message": "ç”ŸæˆæˆåŠŸ"}
        if scheme == "scheme1":
            # è‡ªåŠ¨ç”¨ä»·æ ¼è¡¨å†æ¬¡å¡«å……ä»·æ ¼å’Œå“ç‰Œï¼ˆå¯é€‰ï¼‰
            if auto_fill_price:
                print(f"[QUOTE] è‡ªåŠ¨ç”¨ä»·æ ¼è¡¨å†æ¬¡å¡«å……ä»·æ ¼å’Œå“ç‰Œ...")
                match_quote_with_price_table(standard_xlsx, price_path, brand)
            # å¯¹ standard_xlsx åº”ç”¨æŠ˜æ‰£ï¼ˆå•ä»·Ã—æŠ˜æ‰£ï¼Œæ€»ä»·éšä¹‹å˜æ›´ï¼‰
            try:
                import pandas as pd
                df1 = pd.read_excel(standard_xlsx)
                if 'å•ä»·' in df1.columns:
                    df1['å•ä»·'] = pd.to_numeric(df1['å•ä»·'], errors='coerce') * user_discount
                    if 'æ•°é‡' in df1.columns:
                        qty = pd.to_numeric(df1['æ•°é‡'], errors='coerce').fillna(0)
                        df1['æ€»ä»·'] = (df1['å•ä»·'].fillna(0) * qty).round(2)
                    df1.to_excel(standard_xlsx, index=False)
            except Exception as _:
                pass
            print(f"ğŸ‰ [QUOTE] æŠ¥ä»·å•ç”ŸæˆæˆåŠŸ: {os.path.basename(standard_xlsx)}")
            result_payload.update({"file": os.path.basename(standard_xlsx), "scheme": "scheme1"})
        elif scheme == "scheme2":
            print("[QUOTE] å¼€å§‹ç”Ÿæˆç»“æ„åŒ–æŠ¥ä»·ï¼ˆç¬¬äºŒæ–¹æ¡ˆï¼‰...")
            
            # å¤„ç†ç¨ç‡
            tax_rate_value = 0.0
            if tax_rate == "3%":
                tax_rate_value = 0.03
            elif tax_rate == "13%":
                tax_rate_value = 0.13
            elif tax_rate == "ä¸å«ç¨":
                tax_rate_value = 0.0
            else:
                tax_rate_value = 0.13  # é»˜è®¤13%
            
            structured_file = generate_structured_quote(
                inquiry_path=standard_csv,
                price_path=price_path,
                output_dir=quote_dir,
                customer_id=username,
                customer_name=company_name or company,
                selected_brand=brand,
                discount=user_discount,
                # ä¼ é€’å…¬å¸ä¿¡æ¯
                company_info={
                    "company_name": company_name,
                    "business_contact": business_contact,
                    "contact_phone": contact_phone,
                    "contact_email": contact_email,
                    "customer_header": customer_header,
                    "recipient": recipient,
                    "contact_method": contact_method,
                    "address": address,
                    "tax_rate": tax_rate_value
                }
            )
            # å¯¹ç¬¬äºŒæ–¹æ¡ˆåº”ç”¨æŠ˜æ‰£
            try:
                import pandas as pd
                df2 = pd.read_excel(structured_file)
                if 'å•ä»·' in df2.columns:
                    df2['å•ä»·'] = pd.to_numeric(df2['å•ä»·'], errors='coerce') * user_discount
                    if 'æ•°é‡' in df2.columns:
                        qty = pd.to_numeric(df2['æ•°é‡'], errors='coerce').fillna(0)
                        df2['é‡‘é¢'] = (df2['å•ä»·'].fillna(0) * qty).round(2)
                    df2.to_excel(structured_file, index=False)
            except Exception as _:
                pass
            print(f"ğŸ‰ [QUOTE] ç»“æ„åŒ–æŠ¥ä»·ç”ŸæˆæˆåŠŸ: {os.path.basename(structured_file)}")
            result_payload.update({"structured_file": os.path.basename(structured_file), "scheme": "scheme2"})
            # ä»…è¾“å‡ºæ‰€é€‰æ–¹æ¡ˆï¼šåˆ é™¤æ ‡å‡†æŠ¥ä»·ä¸­é—´æ–‡ä»¶
            try:
                if os.path.exists(standard_xlsx):
                    os.remove(standard_xlsx)
                if os.path.exists(standard_csv):
                    os.remove(standard_csv)
            except Exception:
                pass
        else:
            # éæ³•schemeå€¼ï¼Œå›é€€åˆ°ç¬¬ä¸€æ–¹æ¡ˆ
            if auto_fill_price:
                print(f"[QUOTE] è‡ªåŠ¨ç”¨ä»·æ ¼è¡¨å†æ¬¡å¡«å……ä»·æ ¼å’Œå“ç‰Œ...")
                match_quote_with_price_table(standard_xlsx, price_path, brand)
            try:
                import pandas as pd
                df1 = pd.read_excel(standard_xlsx)
                if 'å•ä»·' in df1.columns:
                    df1['å•ä»·'] = pd.to_numeric(df1['å•ä»·'], errors='coerce') * user_discount
                    if 'æ•°é‡' in df1.columns:
                        qty = pd.to_numeric(df1['æ•°é‡'], errors='coerce').fillna(0)
                        df1['æ€»ä»·'] = (df1['å•ä»·'].fillna(0) * qty).round(2)
                    df1.to_excel(standard_xlsx, index=False)
            except Exception as _:
                pass
            print(f"ğŸ‰ [QUOTE] æŠ¥ä»·å•ç”ŸæˆæˆåŠŸ(å›é€€åˆ°ç¬¬ä¸€æ–¹æ¡ˆ): {os.path.basename(standard_xlsx)}")
            result_payload.update({"file": os.path.basename(standard_xlsx), "scheme": "scheme1"})

        return result_payload

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [QUOTE] ç”ŸæˆæŠ¥ä»·å•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ç”ŸæˆæŠ¥ä»·å•å¤±è´¥: {str(e)}")

@app.post("/api/generate-enhanced-quote")
async def generate_enhanced_quote(
    price_file: str = Form(...),
    inquiry_file: str = Form(...),
    username: str = Depends(verify_credentials)
):
    """ä½¿ç”¨å¢å¼ºä»·æ ¼åŒ¹é…åŠŸèƒ½ç”ŸæˆæŠ¥ä»·å•"""
    try:
        print(f"ğŸš€ [ENHANCED-API] å¼€å§‹å¢å¼ºæŠ¥ä»·ç”Ÿæˆ")
        print(f"ğŸ‘¤ [ENHANCED-API] ç”¨æˆ·: {username}")
        print(f"ğŸ’° [ENHANCED-API] ä»·æ ¼æ–‡ä»¶: {price_file}")
        print(f"ğŸ“‹ [ENHANCED-API] è¯¢ä»·æ–‡ä»¶: {inquiry_file}")
        
        user_dir = os.path.join(DATA_ROOT, username)
        price_path = os.path.join(user_dir, "ä»·æ ¼è¡¨", price_file)
        inquiry_path = os.path.join(user_dir, "è¯¢ä»·è¡¨", inquiry_file)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(price_path):
            raise HTTPException(status_code=404, detail=f"ä»·æ ¼è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {price_file}")
        
        if not os.path.exists(inquiry_path):
            raise HTTPException(status_code=404, detail=f"è¯¢ä»·è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {inquiry_file}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        company_name = Path(price_file).stem  # ä»ä»·æ ¼è¡¨æ–‡ä»¶åæå–å…¬å¸å
        output_filename = f"{timestamp}_{company_name}_å¢å¼ºæŠ¥ä»·.xlsx"
        output_path = os.path.join(user_dir, "æŠ¥ä»·å•", output_filename)
        
        # ä½¿ç”¨å¢å¼ºçš„ä»·æ ¼åŒ¹é…åŠŸèƒ½
        result_file = process_quote_with_enhanced_matching(
            inquiry_file=inquiry_path,
            price_file=price_path,
            output_file=output_path,
            username=username
        )
        
        if result_file and os.path.exists(result_file):
            print(f"âœ… [ENHANCED-API] å¢å¼ºæŠ¥ä»·ç”ŸæˆæˆåŠŸ: {output_filename}")
            return {
                "message": "å¢å¼ºæŠ¥ä»·å•ç”ŸæˆæˆåŠŸ",
                "file": output_filename,
                "enhanced": True
            }
        else:
            raise HTTPException(status_code=500, detail="å¢å¼ºæŠ¥ä»·å•ç”Ÿæˆå¤±è´¥")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [ENHANCED-API] å¢å¼ºæŠ¥ä»·ç”Ÿæˆå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¢å¼ºæŠ¥ä»·ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.post("/api/generate-multi-company-quote")
async def generate_multi_company_quote_api(
    inquiry_file: str = Form(...),
    username: str = Depends(verify_credentials)
):
    """ç”Ÿæˆå¤šå…¬å¸ä»·æ ¼å¯¹æ¯”æŠ¥ä»·å•"""
    try:
        print(f"ğŸš€ [MULTI-API] å¼€å§‹å¤šå…¬å¸æŠ¥ä»·ç”Ÿæˆ")
        print(f"ğŸ‘¤ [MULTI-API] ç”¨æˆ·: {username}")
        print(f"ğŸ“‹ [MULTI-API] è¯¢ä»·æ–‡ä»¶: {inquiry_file}")
        
        user_dir = os.path.join(DATA_ROOT, username)
        inquiry_path = os.path.join(user_dir, "è¯¢ä»·è¡¨", inquiry_file)
        price_dir = os.path.join(user_dir, "ä»·æ ¼è¡¨")
        
        # æ£€æŸ¥è¯¢ä»·æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(inquiry_path):
            raise HTTPException(status_code=404, detail=f"è¯¢ä»·è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {inquiry_file}")
        
        # æ‰«ææ‰€æœ‰ä»·æ ¼è¡¨æ–‡ä»¶
        if not os.path.exists(price_dir):
            raise HTTPException(status_code=404, detail="ä»·æ ¼è¡¨ç›®å½•ä¸å­˜åœ¨")
        
        price_files = {}
        supported_formats = ['.xlsx', '.xls', '.csv']
        
        for filename in os.listdir(price_dir):
            if any(filename.lower().endswith(fmt) for fmt in supported_formats):
                company_name = Path(filename).stem  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºå…¬å¸å
                price_files[company_name] = os.path.join(price_dir, filename)
        
        if not price_files:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°ä»»ä½•ä»·æ ¼è¡¨æ–‡ä»¶")
        
        print(f"ğŸ“Š [MULTI-API] å‘ç°ä»·æ ¼è¡¨: {list(price_files.keys())}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"{timestamp}_å¤šå…¬å¸ä»·æ ¼å¯¹æ¯”.xlsx"
        output_path = os.path.join(user_dir, "æŠ¥ä»·å•", output_filename)
        
        # ä½¿ç”¨å¤šå…¬å¸æŠ¥ä»·åŠŸèƒ½
        result_file = generate_multi_brand_quote(
            inquiry_file=inquiry_path,
            price_files=price_files,
            output_file=output_path,
            username=username
        )
        
        if result_file and os.path.exists(result_file):
            print(f"âœ… [MULTI-API] å¤šå…¬å¸æŠ¥ä»·ç”ŸæˆæˆåŠŸ: {output_filename}")
            return {
                "message": "å¤šå…¬å¸ä»·æ ¼å¯¹æ¯”æŠ¥ä»·å•ç”ŸæˆæˆåŠŸ",
                "file": output_filename,
                "companies": list(price_files.keys()),
                "company_count": len(price_files)
            }
        else:
            raise HTTPException(status_code=500, detail="å¤šå…¬å¸æŠ¥ä»·å•ç”Ÿæˆå¤±è´¥")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [MULTI-API] å¤šå…¬å¸æŠ¥ä»·ç”Ÿæˆå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¤šå…¬å¸æŠ¥ä»·ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/api/download/{file_type}/{filename}")
async def download_file(file_type: str, filename: str, username: str = Depends(verify_credentials)):
    """ä¸‹è½½æ–‡ä»¶"""
    print(f"ğŸ”½ ä¸‹è½½è¯·æ±‚: file_type={file_type}, filename={filename}, username={username}")
    
    if file_type not in ["ä»·æ ¼è¡¨", "è¯¢ä»·è¡¨", "æŠ¥ä»·å•"]:
        print(f"âŒ æ— æ•ˆçš„æ–‡ä»¶ç±»å‹: {file_type}")
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ–‡ä»¶ç±»å‹")
    
    file_path = os.path.join(DATA_ROOT, username, file_type, filename)
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {file_path}")
    print(f"ğŸ“ æ–‡ä»¶å­˜åœ¨: {os.path.exists(file_path)}")
    
    # åˆ—å‡ºç›®å½•å†…å®¹è¿›è¡Œè°ƒè¯•
    dir_path = os.path.join(DATA_ROOT, username, file_type)
    if os.path.exists(dir_path):
        files_in_dir = os.listdir(dir_path)
        print(f"ğŸ“‚ ç›®å½• {dir_path} ä¸­çš„æ–‡ä»¶: {files_in_dir}")
    else:
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
    
    print(f"âœ… å¼€å§‹ä¸‹è½½æ–‡ä»¶: {file_path}")
    return FileResponse(file_path, filename=filename)

@app.post("/api/logout")
async def logout(username: str = Depends(verify_credentials)):
    """é€€å‡ºç™»å½•ï¼Œæ¸…ç†ç”¨æˆ·çš„ä¸´æ—¶æ–‡ä»¶å¤¹"""
    try:
        print(f"ğŸ‘‹ [LOGOUT] ç”¨æˆ·é€€å‡ºç™»å½•: {username}")
        
        # æ¸…ç†ç”¨æˆ·çš„ä¸´æ—¶æ–‡ä»¶å¤¹
        user_dir = os.path.join(DATA_ROOT, username)
        if os.path.exists(user_dir):
            # æŸ¥æ‰¾å¹¶åˆ é™¤æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶å¤¹
            temp_dirs = []
            for item in os.listdir(user_dir):
                item_path = os.path.join(user_dir, item)
                if os.path.isdir(item_path) and (item.startswith("temp_") or "temp_" in item):
                    temp_dirs.append(item_path)
                    print(f"ğŸ” [LOGOUT] å‘ç°ä¸´æ—¶ç›®å½•: {item_path}")
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹
            deleted_count = 0
            for temp_dir in temp_dirs:
                # æœ€å¤šå°è¯•3æ¬¡
                for attempt in range(3):
                    try:
                        print(f"ğŸ—‘ï¸  [LOGOUT] å°è¯•åˆ é™¤ä¸´æ—¶ç›®å½• (å°è¯• {attempt+1}/3): {temp_dir}")
                        
                        # å…ˆå°è¯•æ¸…ç©ºç›®å½•å†…å®¹ï¼Œå†åˆ é™¤ç›®å½•æœ¬èº«
                        if os.path.exists(temp_dir):
                            # åˆ—å‡ºç›®å½•å†…å®¹
                            print(f"ğŸ“‚ [LOGOUT] ç›®å½•å†…å®¹: {os.listdir(temp_dir) if os.path.exists(temp_dir) else 'ç›®å½•ä¸å­˜åœ¨'}")
                            
                            # å°è¯•å¼ºåˆ¶åˆ é™¤
                            if sys.platform == 'win32':
                                # Windowså¹³å°
                                os.system(f'rd /s /q "{temp_dir}"')
                            else:
                                # Unix/Linux/MacOSå¹³å°
                                os.system(f'rm -rf "{temp_dir}"')
                            
                            # æ£€æŸ¥æ˜¯å¦åˆ é™¤æˆåŠŸ
                            if not os.path.exists(temp_dir):
                                print(f"âœ… [LOGOUT] æˆåŠŸåˆ é™¤ä¸´æ—¶ç›®å½•: {temp_dir}")
                                deleted_count += 1
                                break
                            else:
                                print(f"âš ï¸  [LOGOUT] ç³»ç»Ÿå‘½ä»¤åˆ é™¤å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨shutil")
                                shutil.rmtree(temp_dir, ignore_errors=True)
                                
                                if not os.path.exists(temp_dir):
                                    print(f"âœ… [LOGOUT] æˆåŠŸåˆ é™¤ä¸´æ—¶ç›®å½•: {temp_dir}")
                                    deleted_count += 1
                                    break
                        else:
                            print(f"âš ï¸  [LOGOUT] è·³è¿‡ç›®å½•(ä¸å­˜åœ¨): {temp_dir}")
                            break
                    except Exception as e:
                        print(f"âš ï¸  [LOGOUT] åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥ (å°è¯• {attempt+1}/3): {temp_dir}, é”™è¯¯: {e}")
                        import traceback
                        traceback.print_exc()
                        
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        if attempt == 2:
                            print(f"âŒ [LOGOUT] åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥ï¼Œå·²å°è¯•æœ€å¤§æ¬¡æ•°: {temp_dir}")
                        else:
                            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†é‡è¯•
                            time.sleep(0.5)
            
            print(f"ğŸ“Š [LOGOUT] æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count}/{len(temp_dirs)} ä¸ªä¸´æ—¶ç›®å½•")
        else:
            print(f"âš ï¸  [LOGOUT] ç”¨æˆ·ç›®å½•ä¸å­˜åœ¨: {user_dir}")
        
        return {"message": "é€€å‡ºæˆåŠŸ", "cleaned_dirs": deleted_count if 'deleted_count' in locals() else 0}
    except Exception as e:
        print(f"âŒ [LOGOUT] é€€å‡ºç™»å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"é€€å‡ºç™»å½•å¤±è´¥: {str(e)}")

@app.post("/api/admin/cleanup-temp")
async def admin_cleanup_temp(username: str = Depends(verify_credentials)):
    """ç®¡ç†å‘˜åŠŸèƒ½ï¼šæ¸…ç†æ‰€æœ‰ç”¨æˆ·çš„ä¸´æ—¶æ–‡ä»¶å¤¹"""
    # éªŒè¯ç®¡ç†å‘˜æƒé™
    if not is_admin(username):
        raise HTTPException(status_code=403, detail="éœ€è¦ç®¡ç†å‘˜æƒé™")
    
    try:
        print(f"ğŸ§¹ [ADMIN] ç®¡ç†å‘˜ {username} è¯·æ±‚æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶å¤¹")
        
        # éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•
        total_dirs = 0
        deleted_dirs = 0
        failed_dirs = 0
        user_stats = {}
        
        if os.path.exists(DATA_ROOT):
            for user_folder in os.listdir(DATA_ROOT):
                user_dir = os.path.join(DATA_ROOT, user_folder)
                if os.path.isdir(user_dir):
                    user_stats[user_folder] = {"found": 0, "deleted": 0, "failed": 0}
                    
                    # æŸ¥æ‰¾ä¸´æ—¶æ–‡ä»¶å¤¹
                    for item in os.listdir(user_dir):
                        item_path = os.path.join(user_dir, item)
                        if os.path.isdir(item_path) and ("temp_" in item):
                            total_dirs += 1
                            user_stats[user_folder]["found"] += 1
                            print(f"ğŸ” [ADMIN] å‘ç°ä¸´æ—¶ç›®å½•: {item_path}")
                            
                            # å°è¯•åˆ é™¤ï¼Œæœ€å¤š3æ¬¡
                            deleted = False
                            for attempt in range(3):
                                try:
                                    print(f"ğŸ—‘ï¸  [ADMIN] å°è¯•åˆ é™¤ä¸´æ—¶ç›®å½• (å°è¯• {attempt+1}/3): {item_path}")
                                    
                                    # åˆ—å‡ºç›®å½•å†…å®¹
                                    print(f"ğŸ“‚ [ADMIN] ç›®å½•å†…å®¹: {os.listdir(item_path) if os.path.exists(item_path) else 'ç›®å½•ä¸å­˜åœ¨'}")
                                    
                                    # å°è¯•å¼ºåˆ¶åˆ é™¤
                                    if sys.platform == 'win32':
                                        # Windowså¹³å°
                                        os.system(f'rd /s /q "{item_path}"')
                                    else:
                                        # Unix/Linux/MacOSå¹³å°
                                        os.system(f'rm -rf "{item_path}"')
                                    
                                    # æ£€æŸ¥æ˜¯å¦åˆ é™¤æˆåŠŸ
                                    if not os.path.exists(item_path):
                                        print(f"âœ… [ADMIN] æˆåŠŸåˆ é™¤ä¸´æ—¶ç›®å½•: {item_path}")
                                        deleted_dirs += 1
                                        user_stats[user_folder]["deleted"] += 1
                                        deleted = True
                                        break
                                    else:
                                        print(f"âš ï¸  [ADMIN] ç³»ç»Ÿå‘½ä»¤åˆ é™¤å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨shutil")
                                        shutil.rmtree(item_path, ignore_errors=True)
                                        
                                        if not os.path.exists(item_path):
                                            print(f"âœ… [ADMIN] æˆåŠŸåˆ é™¤ä¸´æ—¶ç›®å½•: {item_path}")
                                            deleted_dirs += 1
                                            user_stats[user_folder]["deleted"] += 1
                                            deleted = True
                                            break
                                except Exception as e:
                                    print(f"âš ï¸  [ADMIN] åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥ (å°è¯• {attempt+1}/3): {item_path}, é”™è¯¯: {e}")
                                    
                                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                                    if attempt == 2:
                                        print(f"âŒ [ADMIN] åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥ï¼Œå·²å°è¯•æœ€å¤§æ¬¡æ•°: {item_path}")
                                    else:
                                        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†é‡è¯•
                                        time.sleep(0.5)
                            
                            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥
                            if not deleted:
                                failed_dirs += 1
                                user_stats[user_folder]["failed"] += 1
                                print(f"âŒ [ADMIN] åˆ é™¤ä¸´æ—¶ç›®å½•æœ€ç»ˆå¤±è´¥: {item_path}")
        
        # ç”Ÿæˆç»“æœæŠ¥å‘Š
        result = {
            "message": f"æ¸…ç†å®Œæˆï¼Œå…±å‘ç° {total_dirs} ä¸ªä¸´æ—¶ç›®å½•ï¼ŒæˆåŠŸåˆ é™¤ {deleted_dirs} ä¸ªï¼Œå¤±è´¥ {failed_dirs} ä¸ª",
            "total_found": total_dirs,
            "total_deleted": deleted_dirs,
            "total_failed": failed_dirs,
            "user_stats": user_stats
        }
        
        print(f"ğŸ“Š [ADMIN] {result['message']}")
        return result
    
    except Exception as e:
        print(f"âŒ [ADMIN] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")

def cleanup_temp_directories():
    """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶å¤¹"""
    try:
        print(f"ğŸ§¹ [SYSTEM] ç³»ç»Ÿå¯åŠ¨æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹")
        
        # éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•
        total_dirs = 0
        deleted_dirs = 0
        failed_dirs = 0
        
        if os.path.exists(DATA_ROOT):
            for user_folder in os.listdir(DATA_ROOT):
                user_dir = os.path.join(DATA_ROOT, user_folder)
                if os.path.isdir(user_dir):
                    # æŸ¥æ‰¾ä¸´æ—¶æ–‡ä»¶å¤¹
                    for item in os.listdir(user_dir):
                        item_path = os.path.join(user_dir, item)
                        if os.path.isdir(item_path) and ("temp_" in item):
                            total_dirs += 1
                            print(f"ğŸ” [SYSTEM] å‘ç°ä¸´æ—¶ç›®å½•: {item_path}")
                            
                            # å°è¯•åˆ é™¤
                            try:
                                print(f"ğŸ—‘ï¸  [SYSTEM] å°è¯•åˆ é™¤ä¸´æ—¶ç›®å½•: {item_path}")
                                
                                # å°è¯•å¼ºåˆ¶åˆ é™¤
                                if sys.platform == 'win32':
                                    # Windowså¹³å°
                                    os.system(f'rd /s /q "{item_path}"')
                                else:
                                    # Unix/Linux/MacOSå¹³å°
                                    os.system(f'rm -rf "{item_path}"')
                                
                                # æ£€æŸ¥æ˜¯å¦åˆ é™¤æˆåŠŸ
                                if not os.path.exists(item_path):
                                    print(f"âœ… [SYSTEM] æˆåŠŸåˆ é™¤ä¸´æ—¶ç›®å½•: {item_path}")
                                    deleted_dirs += 1
                                else:
                                    print(f"âš ï¸  [SYSTEM] ç³»ç»Ÿå‘½ä»¤åˆ é™¤å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨shutil")
                                    shutil.rmtree(item_path, ignore_errors=True)
                                    
                                    if not os.path.exists(item_path):
                                        print(f"âœ… [SYSTEM] æˆåŠŸåˆ é™¤ä¸´æ—¶ç›®å½•: {item_path}")
                                        deleted_dirs += 1
                                    else:
                                        print(f"âŒ [SYSTEM] åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥: {item_path}")
                                        failed_dirs += 1
                            except Exception as e:
                                print(f"âŒ [SYSTEM] åˆ é™¤ä¸´æ—¶ç›®å½•å¤±è´¥: {item_path}, é”™è¯¯: {e}")
                                failed_dirs += 1
        
        print(f"ğŸ“Š [SYSTEM] æ¸…ç†å®Œæˆï¼Œå…±å‘ç° {total_dirs} ä¸ªä¸´æ—¶ç›®å½•ï¼ŒæˆåŠŸåˆ é™¤ {deleted_dirs} ä¸ªï¼Œå¤±è´¥ {failed_dirs} ä¸ª")
        return deleted_dirs
    
    except Exception as e:
        print(f"âŒ [SYSTEM] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0

def match_quote_with_price_table(quote_file, price_file, selected_brand=None):
    """
    ç”¨å·²ç”Ÿæˆçš„æŠ¥ä»·å•ä¸ä»·æ ¼è¡¨å†æ¬¡åŒ¹é…ï¼Œç›´æ¥åœ¨æŠ¥ä»·å•çš„ä»·æ ¼åˆ—å¡«å…¥åŒ¹é…åˆ°çš„ä»·æ ¼ï¼ŒæœªåŒ¹é…çš„ä¿æŒç©ºç™½ï¼Œå“ç‰Œåˆ—è¾“å‡ºæ‰€é€‰å“ç‰Œã€‚
    åŒ¹é…æ—¶æ”¯æŒæ¨¡ç³ŠåŒ…å«ã€å»é™¤ç©ºæ ¼ã€å…¨å°å†™ï¼Œéå†æ‰€é€‰å“ç‰Œçš„ä»·æ ¼è¡¨è¡Œï¼Œæ‰¾åˆ°æœ€ä¼˜åŒ¹é…ã€‚
    å¿½ç•¥è¯¢ä»·è¡¨å“ç‰Œï¼Œå…¨éƒ¨ç”¨ selected_brandã€‚
    """
    import pandas as pd
    import re
    quote_df = pd.read_excel(quote_file)
    price_df = pd.read_excel(price_file)

    # è‡ªåŠ¨è¯†åˆ«æ ‡å‡†å‹å·ã€åç§°ã€å“ç‰Œåˆ—
    model_col = None
    for col in ['æ ‡å‡†å‹å·', 'å‹å·', 'äº§å“å‹å·', 'è§„æ ¼å‹å·', 'å‹å·ç¼–ç ']:
        if col in quote_df.columns and col in price_df.columns:
            model_col = col
            break
    name_col = None
    for col in ['åç§°', 'å“å', 'äº§å“åç§°', 'é¡¹ç›®åç§°', 'ç‰©æ–™åç§°']:
        if col in quote_df.columns and col in price_df.columns:
            name_col = col
            break
    brand_col = None
    for col in ['å“ç‰Œ', 'å‚å•†', 'ç”Ÿäº§å‚å®¶']:
        if col in price_df.columns:
            brand_col = col
            break

    def normalize(s):
        if pd.isna(s):
            return ''
        return re.sub(r'\s+', '', str(s)).lower()

    # ç¡®ä¿æ€»ä»·åˆ—å­˜åœ¨
    if 'æ€»ä»·' not in quote_df.columns:
        quote_df['æ€»ä»·'] = ''
        print("[DEBUG] æ·»åŠ æ€»ä»·åˆ—")

    for idx, row in quote_df.iterrows():
        best_score = 0
        best_match = None
        q_model = normalize(row.get(model_col, '')) if model_col else ''
        q_name = normalize(row.get(name_col, '')) if name_col else ''
        q_brand = normalize(selected_brand) if selected_brand else ''  # åªç”¨æ‰€é€‰å“ç‰Œ
        # åªéå†é€‰ä¸­å“ç‰Œçš„è¡Œ
        if selected_brand and brand_col:
            price_rows = price_df[price_df[brand_col].apply(lambda x: normalize(x) == q_brand)]
        else:
            price_rows = price_df
        for _, prow in price_rows.iterrows():
            p_model = normalize(prow.get(model_col, '')) if model_col else ''
            p_name = normalize(prow.get(name_col, '')) if name_col else ''
            p_brand = normalize(prow.get(brand_col, '')) if brand_col else ''
            score = 0
            # å®Œå…¨ç›¸ç­‰ä¼˜å…ˆ
            if q_model and p_model and q_model == p_model:
                score += 10
            elif q_model and p_model and (q_model in p_model or p_model in q_model):
                score += 6
            if q_name and p_name and q_name == p_name:
                score += 5
            elif q_name and p_name and (q_name in p_name or p_name in q_name):
                score += 3
            # å“ç‰Œåªç”¨æ‰€é€‰å“ç‰Œï¼Œä¸å†è€ƒè™‘è¯¢ä»·è¡¨å“ç‰Œ
            if q_brand and p_brand and q_brand == p_brand:
                score += 2
            elif q_brand and p_brand and (q_brand in p_brand or p_brand in q_brand):
                score += 1
            if score > best_score:
                best_score = score
                best_match = prow
        # åŒ¹é…åˆ°åˆ™å†™å…¥å•ä»·å’Œå“ç‰Œï¼Œå¦åˆ™ä¿æŒç©ºç™½
        if best_match is not None and best_score > 0:
            unit_price = best_match.get('å•ä»·', '')
            quote_df.at[idx, 'å•ä»·'] = unit_price
            # è®¡ç®—æ€»ä»· = å•ä»· Ã— æ•°é‡
            try:
                quantity = row.get('æ•°é‡', '')
                if quantity and str(quantity).strip() != '':
                    qty_val = float(quantity)
                    price_val = float(unit_price) if unit_price and str(unit_price).strip() != '' else 0
                    total_val = price_val * qty_val
                    quote_df.at[idx, 'æ€»ä»·'] = total_val
                    print(f"[DEBUG] è¡Œ{idx+1}: {price_val} Ã— {qty_val} = {total_val}")
                else:
                    quote_df.at[idx, 'æ€»ä»·'] = 0.0
                    print(f"[DEBUG] è¡Œ{idx+1}: æ•°é‡ä¸ºç©ºï¼Œæ€»ä»·=0.0")
            except Exception as e:
                print(f"[è­¦å‘Š] æ€»ä»·è®¡ç®—å¤±è´¥: å•ä»·={unit_price}, æ•°é‡={quantity}, é”™è¯¯={e}")
                quote_df.at[idx, 'æ€»ä»·'] = 0.0
            
            if brand_col:
                quote_df.at[idx, 'å“ç‰Œ'] = selected_brand if selected_brand else best_match.get(brand_col, '')
        else:
            # æ²¡åŒ¹é…åˆ°ä¹Ÿè¦æŠŠå“ç‰Œåˆ—å†™æˆæ‰€é€‰å“ç‰Œ
            if brand_col and selected_brand:
                quote_df.at[idx, 'å“ç‰Œ'] = selected_brand
            # æ²¡åŒ¹é…åˆ°ä¹Ÿè¦è®¡ç®—æ€»ä»·ï¼ˆå¦‚æœæœ‰å•ä»·å’Œæ•°é‡ï¼‰
            try:
                unit_price = row.get('å•ä»·', '')
                quantity = row.get('æ•°é‡', '')
                if unit_price and quantity and str(unit_price).strip() != '' and str(quantity).strip() != '':
                    price_val = float(unit_price)
                    qty_val = float(quantity)
                    total_val = price_val * qty_val
                    quote_df.at[idx, 'æ€»ä»·'] = total_val
                    print(f"[DEBUG] æœªåŒ¹é…è¡Œ{idx+1}: {price_val} Ã— {qty_val} = {total_val}")
                else:
                    quote_df.at[idx, 'æ€»ä»·'] = 0.0
                    print(f"[DEBUG] æœªåŒ¹é…è¡Œ{idx+1}: å•ä»·æˆ–æ•°é‡ä¸ºç©ºï¼Œæ€»ä»·=0.0")
            except Exception as e:
                print(f"[è­¦å‘Š] æœªåŒ¹é…è¡Œ{idx+1}: æ€»ä»·è®¡ç®—å¤±è´¥ - {e}")
                quote_df.at[idx, 'æ€»ä»·'] = 0.0
    
    # æœ€ç»ˆéªŒè¯å’Œé‡æ–°è®¡ç®—æ€»ä»·
    print("[DEBUG] å¼€å§‹æœ€ç»ˆæ€»ä»·éªŒè¯å’Œé‡æ–°è®¡ç®—")
    for idx, row in quote_df.iterrows():
        try:
            # åªä½¿ç”¨å•ä»·åˆ—è®¡ç®—æ€»ä»·
            unit_price = row.get('å•ä»·', '')
            quantity = row.get('æ•°é‡', '')
            
            # è®¡ç®—æ€»ä»· = å•ä»· Ã— æ•°é‡
            if unit_price and quantity and str(unit_price).strip() != '' and str(quantity).strip() != '':
                try:
                    price_val = float(unit_price)
                    qty_val = float(quantity)
                    total_val = price_val * qty_val
                    quote_df.at[idx, 'æ€»ä»·'] = total_val
                    print(f"[DEBUG] æœ€ç»ˆè®¡ç®—: è¡Œ{idx+1}, {price_val} Ã— {qty_val} = {total_val}")
                except ValueError as e:
                    print(f"[è­¦å‘Š] æœ€ç»ˆè®¡ç®—å¤±è´¥: è¡Œ{idx+1}, æ•°å€¼è½¬æ¢å¤±è´¥ - {e}")
                    quote_df.at[idx, 'æ€»ä»·'] = 0.0
            else:
                print(f"[è­¦å‘Š] æœ€ç»ˆè®¡ç®—å¤±è´¥: è¡Œ{idx+1}, å•ä»·æˆ–æ•°é‡ä¸ºç©º")
                quote_df.at[idx, 'æ€»ä»·'] = 0.0
                
        except Exception as e:
            print(f"[é”™è¯¯] æœ€ç»ˆè®¡ç®—å¤±è´¥: è¡Œ{idx+1}, è®¡ç®—å¤±è´¥ - {e}")
            quote_df.at[idx, 'æ€»ä»·'] = 0.0
    
    quote_df.to_excel(quote_file, index=False)
    return quote_file

@app.get("/api/price-table/{filename}")
async def get_price_table_content(filename: str, username: str = Depends(verify_credentials)):
    """è·å–ä»·æ ¼è¡¨å†…å®¹"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(file_path)
        
        # å¤„ç†NaNå€¼ï¼Œå°†å…¶æ›¿æ¢ä¸ºNoneï¼Œä»¥ä¾¿JSONåºåˆ—åŒ–
        df_cleaned = df.where(pd.notna(df), None)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        data = {
            "columns": df_cleaned.columns.tolist(),
            "data": df_cleaned.values.tolist(),
            "total_rows": len(df_cleaned),
            "total_columns": len(df_cleaned.columns)
        }
        
        return JSONResponse(content=data)
        
    except Exception as e:
        print(f"âŒ [ERROR] è·å–ä»·æ ¼è¡¨å†…å®¹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»·æ ¼è¡¨å†…å®¹å¤±è´¥: {str(e)}")

@app.post("/api/price-table/{filename}/update")
async def update_price_table_content(
    filename: str, 
    data: Dict[str, Any], 
    username: str = Depends(verify_credentials)
):
    """æ›´æ–°ä»·æ ¼è¡¨å†…å®¹"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ä»è¯·æ±‚æ•°æ®ä¸­æå–åˆ—åå’Œæ•°æ®
        columns = data.get("columns", [])
        rows = data.get("data", [])
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(rows, columns=columns)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        df.to_excel(file_path, index=False)
        
        return JSONResponse(content={"message": "ä»·æ ¼è¡¨æ›´æ–°æˆåŠŸ"})
        
    except Exception as e:
        print(f"âŒ [ERROR] æ›´æ–°ä»·æ ¼è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ä»·æ ¼è¡¨å¤±è´¥: {str(e)}")

@app.delete("/api/price-table/{filename}")
async def delete_price_table(filename: str, username: str = Depends(verify_credentials)):
    """åˆ é™¤ä»·æ ¼è¡¨"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # åˆ é™¤æ–‡ä»¶
        os.remove(file_path)
        
        return JSONResponse(content={"message": "ä»·æ ¼è¡¨åˆ é™¤æˆåŠŸ"})
        
    except Exception as e:
        print(f"âŒ [ERROR] åˆ é™¤ä»·æ ¼è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ä»·æ ¼è¡¨å¤±è´¥: {str(e)}")

@app.post("/api/price-table/{filename}/add-row")
async def add_row_to_price_table(
    filename: str, 
    row_data: Dict[str, Any], 
    username: str = Depends(verify_credentials)
):
    """å‘ä»·æ ¼è¡¨æ·»åŠ æ–°è¡Œ"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¯»å–ç°æœ‰æ•°æ®
        df = pd.read_excel(file_path)
        
        # æ·»åŠ æ–°è¡Œ
        new_row = pd.DataFrame([row_data])
        df = pd.concat([df, new_row], ignore_index=True)
        
        # ä¿å­˜æ–‡ä»¶
        df.to_excel(file_path, index=False)
        
        return JSONResponse(content={"message": "è¡Œæ·»åŠ æˆåŠŸ", "new_row_index": len(df) - 1})
        
    except Exception as e:
        print(f"âŒ [ERROR] æ·»åŠ è¡Œå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ·»åŠ è¡Œå¤±è´¥: {str(e)}")

@app.put("/api/price-table/{filename}/row/{row_index}")
async def update_row_in_price_table(
    filename: str, 
    row_index: int, 
    row_data: Dict[str, Any], 
    username: str = Depends(verify_credentials)
):
    """æ›´æ–°ä»·æ ¼è¡¨ä¸­çš„æŒ‡å®šè¡Œ"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¯»å–ç°æœ‰æ•°æ®
        df = pd.read_excel(file_path)
        
        if row_index >= len(df):
            raise HTTPException(status_code=400, detail="è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´")
        
        # æ›´æ–°æŒ‡å®šè¡Œ
        for column, value in row_data.items():
            if column in df.columns:
                df.at[row_index, column] = value
        
        # ä¿å­˜æ–‡ä»¶
        df.to_excel(file_path, index=False)
        
        return JSONResponse(content={"message": "è¡Œæ›´æ–°æˆåŠŸ"})
        
    except Exception as e:
        print(f"âŒ [ERROR] æ›´æ–°è¡Œå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°è¡Œå¤±è´¥: {str(e)}")

@app.delete("/api/price-table/{filename}/row/{row_index}")
async def delete_row_from_price_table(
    filename: str, 
    row_index: int, 
    username: str = Depends(verify_credentials)
):
    """åˆ é™¤ä»·æ ¼è¡¨ä¸­çš„æŒ‡å®šè¡Œ"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¯»å–ç°æœ‰æ•°æ®
        df = pd.read_excel(file_path)
        
        if row_index >= len(df):
            raise HTTPException(status_code=400, detail="è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´")
        
        # åˆ é™¤æŒ‡å®šè¡Œ
        df = df.drop(row_index).reset_index(drop=True)
        
        # ä¿å­˜æ–‡ä»¶
        df.to_excel(file_path, index=False)
        
        return JSONResponse(content={"message": "è¡Œåˆ é™¤æˆåŠŸ"})
        
    except Exception as e:
        print(f"âŒ [ERROR] åˆ é™¤è¡Œå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤è¡Œå¤±è´¥: {str(e)}")

@app.post("/api/price-table/{filename}/add-column")
async def add_column_to_price_table(
    filename: str, 
    data: Dict[str, Any],
    username: str = Depends(verify_credentials)
):
    """å‘ä»·æ ¼è¡¨æ·»åŠ æ–°åˆ—"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¯»å–ç°æœ‰æ•°æ®
        df = pd.read_excel(file_path)
        
        # ä»è¯·æ±‚æ•°æ®ä¸­è·å–åˆ—å
        column_name = data.get("column_name", "")
        if not column_name:
            raise HTTPException(status_code=400, detail="åˆ—åä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥åˆ—åæ˜¯å¦å·²å­˜åœ¨
        if column_name in df.columns:
            raise HTTPException(status_code=400, detail="åˆ—åå·²å­˜åœ¨")
        
        # æ·»åŠ æ–°åˆ—
        df[column_name] = ""
        
        # ä¿å­˜æ–‡ä»¶
        df.to_excel(file_path, index=False)
        
        return JSONResponse(content={"message": "åˆ—æ·»åŠ æˆåŠŸ"})
        
    except Exception as e:
        print(f"âŒ [ERROR] æ·»åŠ åˆ—å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ·»åŠ åˆ—å¤±è´¥: {str(e)}")

@app.delete("/api/price-table/{filename}/column/{column_name}")
async def delete_column_from_price_table(
    filename: str, 
    column_name: str, 
    username: str = Depends(verify_credentials)
):
    """åˆ é™¤ä»·æ ¼è¡¨ä¸­çš„æŒ‡å®šåˆ—"""
    try:
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        user_dir = os.path.join(DATA_ROOT, username, "ä»·æ ¼è¡¨")
        file_path = os.path.join(user_dir, filename)
        
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è¯»å–ç°æœ‰æ•°æ®
        df = pd.read_excel(file_path)
        
        if column_name not in df.columns:
            raise HTTPException(status_code=400, detail="åˆ—åä¸å­˜åœ¨")
        
        # åˆ é™¤æŒ‡å®šåˆ—
        df = df.drop(columns=[column_name])
        
        # ä¿å­˜æ–‡ä»¶
        df.to_excel(file_path, index=False)
        
        return JSONResponse(content={"message": "åˆ—åˆ é™¤æˆåŠŸ"})
        
    except Exception as e:
        print(f"âŒ [ERROR] åˆ é™¤åˆ—å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤åˆ—å¤±è´¥: {str(e)}")

@app.post("/api/generate-structured-quote")
async def generate_structured_quote_api(
    price_file: str = Form(...),
    inquiry_file: str = Form(...),
    customer_id: str = Form(...),
    customer_name: str = Form(None),
    currency: str = Form("CNY"),
    tax_rate: float = Form(0.13),
    valid_days: int = Form(30),
    lead_time: str = Form("7-10 å¤©"),
    payment_terms: str = Form("æ¬¾åˆ°å‘è´§"),
    sales_contact: str = Form(None),
    sales_phone: str = Form(None),
    sales_email: str = Form(None),
    username: str = Depends(verify_credentials)
):
    try:
        user_dir = os.path.join(DATA_ROOT, username)
        price_path = os.path.join(user_dir, "ä»·æ ¼è¡¨", price_file)
        inquiry_path = os.path.join(user_dir, "è¯¢ä»·è¡¨", inquiry_file)
        output_dir = os.path.join(user_dir, "æŠ¥ä»·å•")
        os.makedirs(output_dir, exist_ok=True)

        if not os.path.exists(price_path):
            raise HTTPException(status_code=404, detail=f"ä»·æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {price_file}")
        if not os.path.exists(inquiry_path):
            raise HTTPException(status_code=404, detail=f"è¯¢ä»·æ–‡ä»¶ä¸å­˜åœ¨: {inquiry_file}")

        output_file = generate_structured_quote(
            inquiry_path=inquiry_path,
            price_path=price_path,
            output_dir=output_dir,
            customer_id=customer_id,
            customer_name=customer_name,
            currency=currency,
            tax_rate=tax_rate,
            valid_days=valid_days,
            lead_time=lead_time,
            payment_terms=payment_terms,
            sales_contact=sales_contact,
            sales_phone=sales_phone,
            sales_email=sales_email,
            discount=user_discount,
        )

        filename = os.path.basename(output_file)
        return {"message": "ç»“æ„åŒ–æŠ¥ä»·å•ç”ŸæˆæˆåŠŸ", "file": filename}
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [STRUCTURED] ç”Ÿæˆç»“æ„åŒ–æŠ¥ä»·å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆç»“æ„åŒ–æŠ¥ä»·å¤±è´¥: {str(e)}")

# -----------------------------
# ç®¡ç†å‘˜è®¾ç½®ç”¨æˆ·æŠ˜æ‰£
# -----------------------------
@app.get("/api/admin/user-discount")
async def admin_get_user_discount(target_user: str = Query(...), username: str = Depends(verify_credentials)):
    if not is_admin(username):
        raise HTTPException(status_code=403, detail="éœ€è¦ç®¡ç†å‘˜æƒé™")
    rules_manager = get_rules_manager()
    discount = rules_manager.get_user_discount(target_user)
    return {"user": target_user, "discount": discount}

@app.post("/api/admin/user-discount")
async def admin_set_user_discount(target_user: str = Form(...), discount: float = Form(...), username: str = Depends(verify_credentials)):
    if not is_admin(username):
        raise HTTPException(status_code=403, detail="éœ€è¦ç®¡ç†å‘˜æƒé™")
    rules_manager = get_rules_manager()
    success = rules_manager.set_user_discount(target_user, discount)
    if not success:
        raise HTTPException(status_code=400, detail="è®¾ç½®æŠ˜æ‰£å¤±è´¥")
    return {"user": target_user, "discount": rules_manager.get_user_discount(target_user)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)